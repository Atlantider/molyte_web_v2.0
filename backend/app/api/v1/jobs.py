"""
Job management API endpoints
"""
from fastapi import APIRouter, Depends, HTTPException, status, BackgroundTasks
from sqlalchemy.orm import Session
from sqlalchemy import func
from typing import List, Dict, Any, Tuple
from datetime import datetime, date, timedelta
from pathlib import Path
import subprocess
from app.database import get_db
from app.models.user import User, UserRole
from app.models.electrolyte import ElectrolyteSystem
from app.models.job import MDJob, JobStatus, DataVisibility
from app.models.qc import QCJob, QCJobStatus
from app.schemas.job import MDJob as MDJobSchema, MDJobCreate, MDJobUpdate, BatchMDJobCreate
from app.dependencies import get_current_active_user
from app.core.logger import logger
from app.core.config import settings
from app.utils.permissions import require_module_access, MODULE_MD
from app.workers.molyte_wrapper import MolyteWrapper
from app.workers.molyte_adapter import convert_electrolyte_to_molyte_format
from app.schemas.accuracy_level import (
    AccuracyLevel,
    apply_accuracy_level,
    get_all_accuracy_levels
)
from app.services.quota_service import QuotaService

router = APIRouter()


def check_job_permission(job: MDJob, current_user: User, allow_premium: bool = False):
    """
    Check if user has permission to access a job

    Args:
        job: MD job
        current_user: Current user
        allow_premium: Whether to allow PREMIUM users (default: False)

    Raises:
        HTTPException: If user doesn't have permission
    """
    if job.user_id == current_user.id:
        return  # Owner always has permission

    if current_user.role == UserRole.ADMIN:
        return  # Admin always has permission

    if allow_premium and current_user.role == UserRole.PREMIUM:
        return  # Premium user has permission if allowed

    raise HTTPException(
        status_code=status.HTTP_403_FORBIDDEN,
        detail="Not enough permissions"
    )


def _submit_job_to_cluster(job: MDJob, electrolyte: ElectrolyteSystem, db: Session) -> None:
    """
    Internal function to submit a job to Slurm cluster

    Args:
        job: MDJob instance
        electrolyte: ElectrolyteSystem instance
        db: Database session

    Raises:
        Exception: If submission fails
    """
    # Convert to molyte format
    job_data = convert_electrolyte_to_molyte_format(
        job_name=job.config.get('job_name', f'MD-{job.id}'),
        job_config=job.config,
        electrolyte_data={
            "name": electrolyte.name,
            "cations": electrolyte.cations,
            "anions": electrolyte.anions,
            "solvents": electrolyte.solvents,
            "additives": getattr(electrolyte, 'additives', None),  # Optional field
            "box_size": electrolyte.box_size,  # ä»ç”µè§£è´¨æ¨¡å‹è·å–ç›’å­å¤§å°
            "temperature": electrolyte.temperature,
            "pressure": electrolyte.pressure,
        }
    )

    logger.info(f"Converted job data for {job_data['name']}")

    # Initialize MolyteWrapper
    wrapper = MolyteWrapper(
        work_base_path=settings.MOLYTE_WORK_BASE_PATH,
        initial_salts_path=settings.MOLYTE_INITIAL_SALTS_PATH,
        ligpargen_path=settings.MOLYTE_LIGPARGEN_PATH,
        packmol_path=settings.MOLYTE_PACKMOL_PATH,
        ltemplify_path=settings.MOLYTE_LTEMPLIFY_PATH,
        moltemplate_path=settings.MOLYTE_MOLTEMPLATE_PATH,
        charge_save_path=settings.MOLYTE_CHARGE_SAVE_PATH
    )

    logger.info(f"Generating LAMMPS input files for {job_data['name']}...")

    # Generate LAMMPS input files
    result = wrapper.generate_lammps_input(
        job_data=job_data,
        generate_atom_mapping=True
    )

    if not result["success"]:
        raise Exception(result.get("error", "Unknown error"))

    logger.info(f"LAMMPS input files generated successfully for {job_data['name']}")

    # Submit to Slurm
    work_dir = result["work_dir"]
    job_script = work_dir / "job.sh"

    if not job_script.exists():
        raise Exception("Job script not found")

    logger.info(f"Submitting job to Slurm: {job_script}")

    # Submit using sbatch
    submit_result = subprocess.run(
        ["sbatch", str(job_script)],
        cwd=str(work_dir),
        capture_output=True,
        text=True
    )

    if submit_result.returncode != 0:
        raise Exception(f"Slurm submission failed: {submit_result.stderr}")

    # Parse Slurm job ID from output
    # Expected output: "Submitted batch job 12345"
    slurm_output = submit_result.stdout.strip()
    slurm_job_id = None

    if "Submitted batch job" in slurm_output:
        slurm_job_id = slurm_output.split()[-1]
        logger.info(f"Slurm job ID: {slurm_job_id}")

    # Update job status and fields
    job.status = JobStatus.QUEUED
    job.slurm_job_id = slurm_job_id  # æ›´æ–° slurm_job_id å­—æ®µ
    job.work_dir = str(work_dir)     # æ›´æ–° work_dir å­—æ®µ

    if job.config is None:
        job.config = {}

    # åŒæ—¶åœ¨ config ä¸­ä¿å­˜ï¼ˆå‘åå…¼å®¹ï¼‰
    job.config["slurm_job_id"] = slurm_job_id
    job.config["work_dir"] = str(work_dir)
    job.config["files"] = result.get("files", {})

    db.commit()

    logger.info(f"Job {job.id} submitted successfully:")
    logger.info(f"  Slurm Job ID: {slurm_job_id}")
    logger.info(f"  Work Directory: {work_dir}")
    logger.info(f"  Status: {job.status}")


def generate_job_name(db: Session, electrolyte_system: "ElectrolyteSystem" = None, temperature: float = None, custom_name: str = None) -> str:
    """
    Generate job name with format: {ç”µè§£æ¶²é…æ–¹å}-MD{é…æ–¹å†…åºå·}-{æ¸©åº¦}

    æ–°å‘½åæ–¹å¼ï¼ˆ2024.12æ›´æ–°ï¼‰:
        - ä½¿ç”¨ç”µè§£æ¶²é…æ–¹åä½œä¸ºåŸºç¡€
        - è¿½åŠ  MD åºå·ï¼ˆè¯¥é…æ–¹ä¸‹çš„ç¬¬å‡ ä¸ª MD ä»»åŠ¡ï¼‰
        - è¿½åŠ æ¸©åº¦ä¿¡æ¯

    Examples:
        - EL-20251202-0014-Li-FSI-MD1-298K (è¯¥é…æ–¹çš„ç¬¬1ä¸ªMDä»»åŠ¡ï¼Œ298K)
        - EL-20251202-0014-Li-FSI-MD2-323K (è¯¥é…æ–¹çš„ç¬¬2ä¸ªMDä»»åŠ¡ï¼Œ323K)
        - EL-20251203-0001-Li-PF6-EC-DMC-MD1-298K

    Args:
        db: Database session
        electrolyte_system: ElectrolyteSystem object
        temperature: Temperature in K (optional, defaults to system temperature)
        custom_name: Optional note (saved separately, not in job name)

    Returns:
        Generated job name
    """
    if not electrolyte_system:
        # æ²¡æœ‰é…æ–¹ä¿¡æ¯æ—¶ï¼Œä½¿ç”¨æ—§æ ¼å¼ä½œä¸ºå›é€€
        import re
        today = date.today()
        date_str = today.strftime('%Y%m%d')
        today_start = datetime.combine(today, datetime.min.time())
        today_end = datetime.combine(today, datetime.max.time())
        count = db.query(func.count(MDJob.id)).filter(
            MDJob.created_at >= today_start,
            MDJob.created_at <= today_end
        ).scalar()
        return f"MD-{date_str}-{count + 1:04d}"

    # ä½¿ç”¨é…æ–¹åä½œä¸ºåŸºç¡€
    electrolyte_name = electrolyte_system.name or f"EL-{electrolyte_system.id}"

    # ç»Ÿè®¡è¯¥é…æ–¹ä¸‹å·²æœ‰çš„ MD ä»»åŠ¡æ•°é‡
    existing_count = db.query(func.count(MDJob.id)).filter(
        MDJob.system_id == electrolyte_system.id
    ).scalar()

    # ç”Ÿæˆé…æ–¹å†…åºå·ï¼ˆä»1å¼€å§‹ï¼‰
    md_seq = existing_count + 1

    # è·å–æ¸©åº¦ä¿¡æ¯ï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„æ¸©åº¦ï¼Œå¦åˆ™ä½¿ç”¨é…æ–¹çš„æ¸©åº¦ï¼‰
    temp = temperature if temperature is not None else electrolyte_system.temperature
    temp_int = int(round(temp)) if temp else 298

    # ç”Ÿæˆä»»åŠ¡å: {é…æ–¹å}-MD{åºå·}-{æ¸©åº¦}K
    job_name = f"{electrolyte_name}-MD{md_seq}-{temp_int}K"

    return job_name


@router.get("/accuracy-levels")
def get_accuracy_levels(
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–æ‰€æœ‰ç²¾åº¦ç­‰çº§é…ç½®

    è¿”å›æ ¼å¼:
    {
        "fast": {
            "name": "å¿«é€Ÿæ¨¡å¼",
            "description": "...",
            "charge_method": "ligpargen",
            "nsteps_npt": 100000,
            ...
        },
        "standard": {...},
        "accurate": {...}
    }
    """
    return get_all_accuracy_levels()


def check_daily_job_limit(db: Session, user_id: int, user_role: str) -> Tuple[bool, int, int]:
    """
    Check if user has reached daily job creation limit

    Args:
        db: Database session
        user_id: User ID
        user_role: User role (ADMIN, PREMIUM, USER)

    Returns:
        tuple: (can_create, current_count, limit)
    """
    # Set limits based on user role
    # Convert to uppercase for comparison
    role_upper = str(user_role).upper()

    if role_upper == "ADMIN" or role_upper == "USERROLE.ADMIN":
        limit = 100
    elif role_upper == "PREMIUM" or role_upper == "USERROLE.PREMIUM":
        limit = 100
    else:  # regular user
        limit = 10

    # Count jobs created today by this user
    today = date.today()
    today_start = datetime.combine(today, datetime.min.time())
    today_end = datetime.combine(today, datetime.max.time())

    count = db.query(func.count(MDJob.id)).filter(
        MDJob.user_id == user_id,
        MDJob.created_at >= today_start,
        MDJob.created_at <= today_end
    ).scalar()

    can_create = count < limit

    return can_create, count, limit


@router.post("/", response_model=MDJobSchema, status_code=status.HTTP_201_CREATED)
def create_md_job(
    job_data: MDJobCreate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Create a new MD job

    Args:
        job_data: MD job creation data
        db: Database session
        current_user: Current authenticated user

    Returns:
        MDJob: Created MD job

    Raises:
        HTTPException: If system not found or no permission
    """
    # Check module access
    require_module_access(current_user, MODULE_MD)

    # Check if electrolyte system exists
    system = db.query(ElectrolyteSystem).filter(
        ElectrolyteSystem.id == job_data.system_id
    ).first()
    
    if not system:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Electrolyte system not found"
        )
    
    # Check permission
    if system.project.user_id != current_user.id and current_user.role != UserRole.ADMIN:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Not enough permissions"
        )

    # Check user quota
    has_quota, message = QuotaService.check_quota(current_user, 1.0, db)
    if not has_quota:
        raise HTTPException(
            status_code=status.HTTP_429_TOO_MANY_REQUESTS,
            detail=message
        )

    # ç”Ÿæˆä»»åŠ¡åç§°ï¼ˆæ ¼å¼ï¼š{é…æ–¹å}-MD{åºå·}-{æ¸©åº¦}Kï¼‰
    job_name = generate_job_name(db, electrolyte_system=system, temperature=job_data.temperature)

    # ç”¨æˆ·è¾“å…¥çš„è‡ªå®šä¹‰åç§°ä¿å­˜ä¸ºå¤‡æ³¨ä¿¡æ¯
    user_note = job_data.job_name.strip() if job_data.job_name and job_data.job_name.strip() else None

    # æ„å»ºé…ç½®å‚æ•°
    config = {
        "job_name": job_name,
        "user_note": user_note,  # ç”¨æˆ·å¤‡æ³¨ï¼ˆä¸å½±å“ä»»åŠ¡åï¼‰
        "nsteps_npt": job_data.nsteps_npt,
        "nsteps_nvt": job_data.nsteps_nvt,
        "timestep": job_data.timestep,
        "temperature": job_data.temperature,
        "pressure": job_data.pressure,
        "freq_trj_npt": job_data.freq_trj_npt,
        "freq_trj_nvt": job_data.freq_trj_nvt,
        "thermo_freq": job_data.thermo_freq,
        # ç”µè·è®¡ç®—æ–¹æ³•ï¼ˆä»…è‡ªå®šä¹‰æ¨¡å¼æœ‰æ•ˆï¼‰
        "charge_method": job_data.charge_method if job_data.charge_method else None,
        # Slurm èµ„æºé…ç½®
        "slurm_partition": job_data.slurm_partition or "cpu",
        "slurm_nodes": job_data.slurm_nodes or 1,
        "slurm_ntasks": job_data.slurm_ntasks or 8,
        "slurm_cpus_per_task": job_data.slurm_cpus_per_task or 8,
        "slurm_time": job_data.slurm_time or 7200,
        # QCè®¡ç®—é€‰é¡¹
        "qc_enabled": job_data.qc_options.enabled if job_data.qc_options else False,
        "qc_accuracy_level": job_data.qc_options.accuracy_level if job_data.qc_options and job_data.qc_options.enabled else None,
        # æ”¯æŒå¤šé€‰æ³›å‡½ã€åŸºç»„ã€æº¶å‰‚æ¨¡å‹å’Œæº¶å‰‚
        "qc_functionals": job_data.qc_options.functionals if job_data.qc_options and job_data.qc_options.enabled else None,
        "qc_basis_sets": job_data.qc_options.basis_sets if job_data.qc_options and job_data.qc_options.enabled else None,
        "qc_solvent_models": job_data.qc_options.solvent_models if job_data.qc_options and job_data.qc_options.enabled else None,
        "qc_solvents": job_data.qc_options.solvents if job_data.qc_options and job_data.qc_options.enabled else None,
        # å…¼å®¹æ—§ç‰ˆå•é€‰å­—æ®µ
        "qc_functional": job_data.qc_options.functional if job_data.qc_options and job_data.qc_options.enabled else None,
        "qc_basis_set": job_data.qc_options.basis_set if job_data.qc_options and job_data.qc_options.enabled else None,
        "qc_solvent_model": job_data.qc_options.solvent_model if job_data.qc_options and job_data.qc_options.enabled else None,
        "qc_solvent_name": job_data.qc_options.solvent_name if job_data.qc_options and job_data.qc_options.enabled else None,
        "qc_use_recommended_params": job_data.qc_options.use_recommended_params if job_data.qc_options and job_data.qc_options.enabled else None,
        # é…æ–¹å¿«ç…§æ•°æ®ï¼ˆä¿å­˜åˆ›å»ºä»»åŠ¡æ—¶çš„é…æ–¹çŠ¶æ€ï¼Œé¿å…åç»­ä¿®æ”¹é…æ–¹å½±å“å†å²ä»»åŠ¡æ˜¾ç¤ºï¼‰
        "system_snapshot": {
            "name": system.name,
            "cations": system.cations,
            "anions": system.anions,
            "solvents": system.solvents,
            "box_size": system.box_size,
            "temperature": system.temperature,
            "pressure": system.pressure,
            "force_field": system.force_field,
        }
    }

    # åº”ç”¨ç²¾åº¦ç­‰çº§é…ç½®
    accuracy_level = job_data.accuracy_level or AccuracyLevel.STANDARD
    config = apply_accuracy_level(config, accuracy_level)

    logger.info(f"Applied accuracy level '{accuracy_level.value}' to job {job_name}")
    logger.info(f"QC options: enabled={config.get('qc_enabled')}, qc_options={job_data.qc_options}")
    logger.info(f"  Charge method: {config.get('charge_method')}")
    logger.info(f"  NPT steps: {config.get('nsteps_npt')}, NVT steps: {config.get('nsteps_nvt')}")

    # æ ¹æ® submit_to_cluster å†³å®šåˆå§‹çŠ¶æ€
    # CREATED: åªä¿å­˜ï¼Œç­‰å¾…ç”¨æˆ·åç»­æ‰‹åŠ¨æäº¤
    # SUBMITTED: ç›´æ¥æäº¤ï¼Œç­‰å¾… Worker æ‹‰å–æ‰§è¡Œ
    if job_data.submit_to_cluster:
        initial_status = JobStatus.SUBMITTED
        config["submitted_at"] = datetime.now().isoformat()
        config["submitted_by"] = current_user.username
        logger.info(f"Job will be submitted to cluster immediately")
    else:
        initial_status = JobStatus.CREATED
        logger.info(f"Job saved as draft, waiting for manual submission")

    # Create MD job
    # è·å–ç”¨æˆ·çš„æœ€å¤§å»¶æœŸå¹´æ•°
    from app.models.user import USER_TYPE_QUOTAS
    max_delay_years = USER_TYPE_QUOTAS.get(current_user.user_type, {}).get("max_delay_years", 1)
    default_delay_until = datetime.utcnow() + timedelta(days=365 * max_delay_years)

    db_job = MDJob(
        system_id=job_data.system_id,
        user_id=current_user.id,
        status=initial_status,
        progress=0.0,
        config=config,
        visibility=DataVisibility.DELAYED,
        visibility_delay_until=default_delay_until
    )

    db.add(db_job)
    db.commit()
    db.refresh(db_job)

    logger.info(f"MD job created: ID={db_job.id} by {current_user.username}, status={initial_status}")

    # å¦‚æœå¯ç”¨äº†QCè®¡ç®—ï¼Œåˆ›å»ºQCä»»åŠ¡
    if job_data.qc_options and job_data.qc_options.enabled:
        try:
            _create_qc_jobs_for_md(db, db_job, system, current_user, job_data.qc_options)

            # å¦‚æœ MD ä»»åŠ¡ç›´æ¥æäº¤ï¼ŒQC ä»»åŠ¡ä¹Ÿåº”è¯¥ç›´æ¥æäº¤
            if job_data.submit_to_cluster:
                from app.models.qc import QCJob, QCJobStatus
                qc_jobs = db.query(QCJob).filter(
                    QCJob.md_job_id == db_job.id,
                    QCJob.status == QCJobStatus.CREATED
                ).all()
                for qc_job in qc_jobs:
                    qc_job.status = QCJobStatus.SUBMITTED
                    qc_job.config = qc_job.config or {}
                    qc_job.config["submitted_at"] = datetime.now().isoformat()
                    qc_job.config["submitted_by"] = current_user.username
                db.commit()
                logger.info(f"Auto-submitted {len(qc_jobs)} QC jobs for MD job {db_job.id}")

        except Exception as e:
            logger.error(f"Failed to create QC jobs for MD job {db_job.id}: {e}")
            # QCä»»åŠ¡åˆ›å»ºå¤±è´¥ä¸å½±å“MDä»»åŠ¡

    return db_job


@router.post("/batch")
def batch_create_md_jobs(
    batch_data: BatchMDJobCreate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    æ‰¹é‡åˆ›å»ºMDä»»åŠ¡

    Args:
        batch_data: æ‰¹é‡åˆ›å»ºè¯·æ±‚æ•°æ®ï¼ˆåŒ…å«system_idså’Œä»»åŠ¡é…ç½®ï¼‰
        db: æ•°æ®åº“ä¼šè¯
        current_user: å½“å‰ç”¨æˆ·

    Returns:
        æ‰¹é‡åˆ›å»ºç»“æœ
    """
    from fastapi.responses import JSONResponse

    # æ£€æŸ¥ç”¨æˆ·é…é¢
    has_quota, message = QuotaService.check_quota(current_user, 1.0, db)
    if not has_quota:
        return JSONResponse(
            status_code=403,
            content={
                "success": False,
                "message": message,
                "quota_exceeded": True
            }
        )

    # æ£€æŸ¥æ‰¹é‡åˆ›å»ºæ˜¯å¦ä¼šè¶…è¿‡æ¯æ—¥ä»»åŠ¡é™åˆ¶
    quota_details = quota_check.get("details", {})
    today_jobs = quota_details.get("today_jobs", 0)
    daily_limit = quota_details.get("daily_limit", 999)
    remaining = daily_limit - today_jobs

    if len(batch_data.system_ids) > remaining:
        return JSONResponse(
            status_code=403,
            content={
                "success": False,
                "message": f"æ‰¹é‡åˆ›å»º {len(batch_data.system_ids)} ä¸ªä»»åŠ¡å°†è¶…è¿‡æ¯æ—¥é™åˆ¶ï¼ˆå‰©ä½™é…é¢ï¼š{remaining}ï¼‰",
                "quota_exceeded": True,
                "requested": len(batch_data.system_ids),
                "remaining": remaining
            }
        )

    results = {
        "success": True,
        "total": len(batch_data.system_ids),
        "success_count": 0,
        "failed_count": 0,
        "success_jobs": [],
        "errors": []
    }

    for system_id in batch_data.system_ids:
        try:
            # ä¸ºæ¯ä¸ªé…æ–¹åˆ›å»ºMDä»»åŠ¡
            job_create = MDJobCreate(
                system_id=system_id,
                job_name=batch_data.job_name,
                accuracy_level=batch_data.accuracy_level,
                charge_method=batch_data.charge_method,
                nsteps_npt=batch_data.nsteps_npt,
                nsteps_nvt=batch_data.nsteps_nvt,
                timestep=batch_data.timestep,
                temperature=batch_data.temperature,
                pressure=batch_data.pressure,
                freq_trj_npt=batch_data.freq_trj_npt,
                freq_trj_nvt=batch_data.freq_trj_nvt,
                thermo_freq=batch_data.thermo_freq,
                submit_to_cluster=batch_data.submit_to_cluster,
                slurm_partition=batch_data.slurm_partition,
                slurm_nodes=batch_data.slurm_nodes,
                slurm_ntasks=batch_data.slurm_ntasks,
                slurm_cpus_per_task=batch_data.slurm_cpus_per_task,
                slurm_time=batch_data.slurm_time,
                qc_options=batch_data.qc_options
            )

            md_job = create_md_job(job_create, db, current_user)

            results["success_count"] += 1
            results["success_jobs"].append({
                "system_id": system_id,
                "job_id": md_job.id,
                "job_name": md_job.config.get('job_name', 'N/A')
            })

        except HTTPException as e:
            results["failed_count"] += 1
            error_detail = e.detail if isinstance(e.detail, str) else str(e.detail)
            results["errors"].append({
                "system_id": system_id,
                "error": error_detail
            })
        except Exception as e:
            results["failed_count"] += 1
            results["errors"].append({
                "system_id": system_id,
                "error": str(e)
            })

    if results["failed_count"] > 0:
        results["success"] = False

    return JSONResponse(content=results)


def _get_recommended_qc_params(mol_type: str, base_options) -> dict:
    """
    æ ¹æ®åˆ†å­ç±»å‹è·å–æ¨èçš„QCè®¡ç®—å‚æ•°

    Args:
        mol_type: åˆ†å­ç±»å‹ (solvent, cation, anion)
        base_options: ç”¨æˆ·è®¾ç½®çš„åŸºç¡€é€‰é¡¹

    Returns:
        dict: åŒ…å« basis_set, functional, solvent_model, solvent_name çš„å­—å…¸
    """
    # åŸºç¡€å‚æ•°
    params = {
        "basis_set": base_options.basis_set or "6-31++g(d,p)",
        "functional": base_options.functional or "B3LYP",
        "solvent_model": base_options.solvent_model or "pcm",
        "solvent_name": base_options.solvent_name or "water",
        "recommendation_reason": ""
    }

    # å¦‚æœä¸ä½¿ç”¨æ¨èå‚æ•°ï¼Œç›´æ¥è¿”å›ç”¨æˆ·è®¾ç½®
    if not getattr(base_options, 'use_recommended_params', True):
        params["recommendation_reason"] = "ä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰å‚æ•°"
        return params

    if mol_type == "anion":
        # é˜´ç¦»å­éœ€è¦å¼¥æ•£å‡½æ•°æ¥æè¿°æ‰©æ•£çš„ç”µå­äº‘
        # æ¨èä½¿ç”¨ 6-31++G(d,p) æˆ– aug-cc-pVDZ
        if "+" not in params["basis_set"]:
            params["basis_set"] = "6-31++g(d,p)"
        params["recommendation_reason"] = "é˜´ç¦»å­ä½¿ç”¨å¸¦å¼¥æ•£å‡½æ•°(++)çš„åŸºç»„ï¼Œä»¥æ›´å¥½åœ°æè¿°æ‰©æ•£çš„ç”µå­å¯†åº¦"
        # é˜´ç¦»å­é€šå¸¸éœ€è¦éšå¼æº¶å‰‚æ¨¡å‹æ¥ç¨³å®š
        if params["solvent_model"] == "gas":
            params["solvent_model"] = "pcm"
            params["recommendation_reason"] += "ï¼›æ°”ç›¸é˜´ç¦»å­å¯èƒ½ä¸ç¨³å®šï¼Œå»ºè®®ä½¿ç”¨PCMæº¶å‰‚æ¨¡å‹"

    elif mol_type == "cation":
        # é˜³ç¦»å­é€šå¸¸ç”µå­æ›´åŠ ç´§å‡‘ï¼Œæ ‡å‡†åŸºç»„å³å¯
        # ä½†ä»æ¨èä½¿ç”¨æåŒ–å‡½æ•°
        if "d" not in params["basis_set"].lower() and "p" not in params["basis_set"].lower():
            params["basis_set"] = "6-31g(d,p)"
        params["recommendation_reason"] = "é˜³ç¦»å­ä½¿ç”¨å¸¦æåŒ–å‡½æ•°çš„åŸºç»„"

    else:  # solvent
        # ä¸­æ€§æº¶å‰‚åˆ†å­ä½¿ç”¨æ ‡å‡†å‚æ•°
        params["recommendation_reason"] = "ä¸­æ€§åˆ†å­ä½¿ç”¨æ ‡å‡†è®¡ç®—å‚æ•°"

    return params


def _calculate_spin_multiplicity(smiles: str, charge: int) -> int:
    """
    æ ¹æ®SMILESå’Œç”µè·è®¡ç®—è‡ªæ—‹å¤šé‡åº¦

    è‡ªæ—‹å¤šé‡åº¦ = 2S + 1ï¼Œå…¶ä¸­Sæ˜¯æ€»è‡ªæ—‹é‡å­æ•°
    - é—­å£³å±‚åˆ†å­ï¼ˆå¶æ•°ç”µå­ï¼‰: S=0, è‡ªæ—‹å¤šé‡åº¦=1
    - å¼€å£³å±‚åˆ†å­ï¼ˆå¥‡æ•°ç”µå­ï¼‰: S=0.5, è‡ªæ—‹å¤šé‡åº¦=2
    - è‡ªç”±åŸº: æ ¹æ®æœªé…å¯¹ç”µå­æ•°è®¡ç®—

    æ³¨æ„ï¼šå¿…é¡»æ·»åŠ æ°¢åŸå­åå†è®¡ç®—ç”µå­æ•°ï¼
    """
    try:
        from rdkit import Chem
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            logger.warning(f"æ— æ³•è§£æSMILES: {smiles[:50]}..., ä½¿ç”¨é»˜è®¤è‡ªæ—‹å¤šé‡åº¦1")
            return 1

        # æ·»åŠ æ°¢åŸå­ä»¥è·å¾—å®Œæ•´çš„ç”µå­æ•°
        mol_with_h = Chem.AddHs(mol)

        # è®¡ç®—æ€»ç”µå­æ•°
        total_electrons = sum(atom.GetAtomicNum() for atom in mol_with_h.GetAtoms())
        total_electrons -= charge  # ç”µè·å½±å“ç”µå­æ•°

        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜¾å¼è‡ªç”±åŸº
        num_radical_electrons = sum(atom.GetNumRadicalElectrons() for atom in mol.GetAtoms())

        if num_radical_electrons > 0:
            # æœ‰æ˜¾å¼è‡ªç”±åŸº
            spin_multiplicity = num_radical_electrons + 1
        else:
            # æ ¹æ®ç”µå­æ•°åˆ¤æ–­
            # å¶æ•°ç”µå­ -> é—­å£³å±‚ -> è‡ªæ—‹å¤šé‡åº¦ = 1
            # å¥‡æ•°ç”µå­ -> å¼€å£³å±‚ -> è‡ªæ—‹å¤šé‡åº¦ = 2
            if total_electrons % 2 == 0:
                spin_multiplicity = 1  # å•é‡æ€
            else:
                spin_multiplicity = 2  # äºŒé‡æ€

        logger.debug(f"Spin calculation for {smiles[:30]}...: charge={charge}, electrons={total_electrons}, radicals={num_radical_electrons}, spin={spin_multiplicity}")
        return spin_multiplicity

    except ImportError:
        logger.warning(f"RDKitæœªå®‰è£…ï¼Œä½¿ç”¨é»˜è®¤è‡ªæ—‹å¤šé‡åº¦1 (smiles: {smiles[:30]}...)")
        return 1  # é»˜è®¤å•é‡æ€
    except Exception as e:
        logger.warning(f"è®¡ç®—è‡ªæ—‹å¤šé‡åº¦å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤å€¼1")
        return 1  # é»˜è®¤å•é‡æ€


def _create_qc_jobs_for_md(db: Session, md_job: MDJob, system: ElectrolyteSystem,
                           user: User, qc_options):
    """
    ä¸ºMDä»»åŠ¡åˆ›å»ºå…³è”çš„QCä»»åŠ¡

    Args:
        db: æ•°æ®åº“ä¼šè¯
        md_job: MDä»»åŠ¡
        system: ç”µè§£è´¨ç³»ç»Ÿ
        user: ç”¨æˆ·
        qc_options: QCé€‰é¡¹
    """
    # ä»ç”µè§£è´¨é…æ–¹çš„JSONBå­—æ®µä¸­æå–åˆ†å­ä¿¡æ¯
    # æ ¼å¼: [{"name": "...", "smiles": "...", ...}, ...]
    molecules_to_calc = []  # [(smiles, name, mol_type, charge), ...]
    seen_smiles = set()

    if qc_options.molecules:
        # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„åˆ†å­åˆ—è¡¨
        for smiles in qc_options.molecules:
            if smiles and smiles not in seen_smiles:
                molecules_to_calc.append((smiles, f"custom_{len(molecules_to_calc)}", "custom", 0))
                seen_smiles.add(smiles)
    else:
        # ä»ç”µè§£è´¨é…æ–¹ä¸­æå–æ‰€æœ‰åˆ†å­
        # æº¶å‰‚åˆ†å­
        if system.solvents:
            for sol in system.solvents:
                smiles = sol.get("smiles")
                name = sol.get("name", "solvent")
                if smiles and smiles not in seen_smiles:
                    molecules_to_calc.append((smiles, name, "solvent", 0))
                    seen_smiles.add(smiles)

        # é˜³ç¦»å­
        if system.cations:
            for cat in system.cations:
                smiles = cat.get("smiles")
                name = cat.get("name", "cation")
                charge = cat.get("charge")  # å°è¯•ä»æ•°æ®ä¸­è·å–ç”µè·
                if charge is None:  # å¦‚æœæ²¡æœ‰è®¾ç½®æˆ–ä¸ºNoneï¼Œä½¿ç”¨é»˜è®¤å€¼+1
                    charge = 1
                if smiles and smiles not in seen_smiles:
                    molecules_to_calc.append((smiles, name, "cation", charge))
                    seen_smiles.add(smiles)

        # é˜´ç¦»å­
        if system.anions:
            for an in system.anions:
                smiles = an.get("smiles")
                name = an.get("name", "anion")
                charge = an.get("charge")  # å°è¯•ä»æ•°æ®ä¸­è·å–ç”µè·
                if charge is None:  # å¦‚æœæ²¡æœ‰è®¾ç½®æˆ–ä¸ºNoneï¼Œä½¿ç”¨é»˜è®¤å€¼-1
                    charge = -1
                if smiles and smiles not in seen_smiles:
                    molecules_to_calc.append((smiles, name, "anion", charge))
                    seen_smiles.add(smiles)

    # è·å–è®¡ç®—å‚æ•°åˆ—è¡¨ï¼ˆæ”¯æŒå¤šé€‰ï¼‰
    basis_sets = getattr(qc_options, 'basis_sets', None) or [getattr(qc_options, 'basis_set', '6-31++g(d,p)')]
    functionals = getattr(qc_options, 'functionals', None) or [getattr(qc_options, 'functional', 'B3LYP')]
    solvent_models = getattr(qc_options, 'solvent_models', None) or [getattr(qc_options, 'solvent_model', 'pcm')]
    solvents = getattr(qc_options, 'solvents', None) or [getattr(qc_options, 'solvent_name', 'Water')]

    # è·å–è‡ªå®šä¹‰æº¶å‰‚å‚æ•°ï¼ˆå¦‚æœæœ‰ï¼‰
    custom_solvent_params = getattr(qc_options, 'custom_solvent', None)
    if custom_solvent_params and hasattr(custom_solvent_params, 'model_dump'):
        custom_solvent_params = custom_solvent_params.model_dump()
    elif custom_solvent_params and hasattr(custom_solvent_params, 'dict'):
        custom_solvent_params = custom_solvent_params.dict()

    # æ„å»ºæº¶å‰‚ç»„åˆ
    # å¦‚æœæº¶å‰‚æ¨¡å‹åŒ…å« gasï¼Œåˆ™åªä½¿ç”¨ gasï¼ˆä¸éœ€è¦æº¶å‰‚ï¼‰
    # å¦‚æœæº¶å‰‚æ¨¡å‹åŒ…å« customï¼Œä½¿ç”¨è‡ªå®šä¹‰æº¶å‰‚å‚æ•°
    # å¦åˆ™ï¼Œä¸ºæ¯ä¸ªæº¶å‰‚æ¨¡å‹å’Œæº¶å‰‚çš„ç»„åˆåˆ›å»ºä»»åŠ¡
    solvent_combinations = []
    if 'gas' in solvent_models:
        solvent_combinations.append(('gas', None, None))

    # å¦‚æœåŒ…å« customï¼Œæ·»åŠ è‡ªå®šä¹‰æº¶å‰‚ç»„åˆ
    if 'custom' in solvent_models and custom_solvent_params:
        solvent_combinations.append(('custom', 'Custom', custom_solvent_params))

    # ä¸º PCM/SMD æ¨¡å‹åˆ›å»ºæº¶å‰‚ç»„åˆ
    standard_models = [m for m in solvent_models if m not in ['gas', 'custom']]
    for model in standard_models:
        for solvent in solvents:
            solvent_combinations.append((model, solvent, None))

    # å¦‚æœæ²¡æœ‰ä»»ä½•ç»„åˆï¼Œä½¿ç”¨é»˜è®¤å€¼
    if not solvent_combinations:
        solvent_combinations = [('pcm', 'Water', None)]

    # è®¡ç®—æ€»ä»»åŠ¡æ•°ï¼šåˆ†å­ Ã— æ³›å‡½ Ã— åŸºç»„ Ã— æº¶å‰‚ç»„åˆ
    total_jobs = len(molecules_to_calc) * len(functionals) * len(basis_sets) * len(solvent_combinations)
    logger.info(f"Creating {total_jobs} QC jobs ({len(molecules_to_calc)} molecules Ã— {len(functionals)} functionals Ã— {len(basis_sets)} basis sets Ã— {len(solvent_combinations)} solvent combinations) for MD job {md_job.id}")

    for smiles, mol_name, mol_type, charge in molecules_to_calc:
        # è®¡ç®—è‡ªæ—‹å¤šé‡åº¦ï¼ˆå¯¹æ‰€æœ‰å‚æ•°ç»„åˆéƒ½ç›¸åŒï¼‰
        spin_multiplicity = _calculate_spin_multiplicity(smiles, charge)
        logger.info(f"ğŸ” è®¡ç®—è‡ªæ—‹å¤šé‡åº¦: {mol_name} (SMILES: {smiles[:50]}..., charge: {charge}) -> spin_multiplicity = {spin_multiplicity}")

        # éå†æ‰€æœ‰å‚æ•°ç»„åˆï¼ˆç¬›å¡å°”ç§¯ï¼‰
        for functional in functionals:
            for basis_set in basis_sets:
                for solvent_model, solvent_name, custom_params in solvent_combinations:
                    # æ ¹æ®åˆ†å­ç±»å‹è·å–æ¨èå‚æ•°
                    params = _get_recommended_qc_params(mol_type, qc_options)

                    # ä½¿ç”¨å½“å‰å¾ªç¯çš„å‚æ•°è¦†ç›–æ¨èå‚æ•°
                    params["basis_set"] = basis_set
                    params["functional"] = functional
                    params["solvent_model"] = solvent_model
                    params["solvent_name"] = solvent_name

                    # æ„å»ºæº¶å‰‚é…ç½®
                    solvent_config = None
                    if params["solvent_model"] == "custom" and custom_params:
                        # è‡ªå®šä¹‰æº¶å‰‚é…ç½®
                        solvent_config = {
                            "model": "custom",
                            "solvent_name": "Custom",
                            **custom_params  # åŒ…å« eps, eps_inf ç­‰å‚æ•°
                        }
                    elif params["solvent_model"] != "gas":
                        # æ ‡å‡† PCM/SMD æº¶å‰‚é…ç½®
                        solvent_config = {
                            "model": params["solvent_model"],
                            "solvent_name": params["solvent_name"]
                        }

                    # æ„å»ºä»»åŠ¡åç§°ï¼ˆåŒ…å«æ‰€æœ‰å‚æ•°ä»¥åŒºåˆ†ï¼‰
                    # æ ¼å¼: åˆ†å­å-æ³›å‡½-åŸºç»„-æº¶å‰‚æ¨¡å‹-æº¶å‰‚
                    # ç»Ÿä¸€ä½¿ç”¨è¿å­—ç¬¦ï¼Œç§»é™¤ç©ºæ ¼å’Œæ–œæ 
                    clean_mol_name = mol_name.replace(' ', '-').replace('/', '-')
                    clean_basis = basis_set.replace('(', '').replace(')', '').replace('+', 'p').replace(' ', '-').replace('/', '-')
                    name_parts = [clean_mol_name, functional, clean_basis]
                    if solvent_model == 'gas':
                        name_parts.append('gas')
                    elif solvent_model == 'custom':
                        eps_val = custom_params.get('eps', 0) if custom_params else 0
                        name_parts.extend(['custom', f'eps{eps_val}'])
                    else:
                        clean_solvent = solvent_name.replace(' ', '-').replace('/', '-')
                        name_parts.extend([solvent_model, clean_solvent])
                    job_mol_name = '-'.join(name_parts)

                    # ======== æŸ¥é‡é€»è¾‘ ========
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå‚æ•°çš„QCä»»åŠ¡ï¼ˆåŒ…æ‹¬å…¶ä»–ç”¨æˆ·çš„å·²å®Œæˆä»»åŠ¡ï¼‰
                    from sqlalchemy import or_

                    duplicate_query = db.query(QCJob).filter(
                        QCJob.smiles == smiles,
                        QCJob.functional == functional,
                        QCJob.basis_set == basis_set,
                        QCJob.charge == charge,
                        QCJob.spin_multiplicity == spin_multiplicity,
                        QCJob.is_deleted == False
                    )

                    # åŒ¹é…æº¶å‰‚é…ç½®
                    if solvent_model == 'gas':
                        duplicate_query = duplicate_query.filter(
                            or_(
                                QCJob.solvent_model == 'gas',
                                QCJob.solvent_model.is_(None)
                            )
                        )
                    elif solvent_model == 'custom':
                        # è‡ªå®šä¹‰æº¶å‰‚ï¼šéœ€è¦åŒ¹é…æ‰€æœ‰è‡ªå®šä¹‰å‚æ•°
                        duplicate_query = duplicate_query.filter(
                            QCJob.solvent_model == 'custom'
                        )
                        # åŒ¹é…è‡ªå®šä¹‰æº¶å‰‚çš„å…³é”®å‚æ•°ï¼ˆeps æ˜¯æœ€é‡è¦çš„ï¼‰
                        if custom_params:
                            eps_val = custom_params.get('eps')
                            if eps_val is not None:
                                try:
                                    duplicate_query = duplicate_query.filter(
                                        QCJob.config['solvent_config']['eps'].astext == str(eps_val)
                                    )
                                except (KeyError, TypeError):
                                    # å¦‚æœconfigæˆ–solvent_configä¸å­˜åœ¨ï¼Œè·³è¿‡è¿™ä¸ªè¿‡æ»¤æ¡ä»¶
                                    pass
                    else:
                        duplicate_query = duplicate_query.filter(
                            QCJob.solvent_model == solvent_model
                        )
                        if solvent_name:
                            duplicate_query = duplicate_query.filter(
                                QCJob.solvent_name == solvent_name
                            )

                    existing_job = duplicate_query.first()

                    # å¯¹äºè‡ªå®šä¹‰æº¶å‰‚ï¼Œé¢å¤–éªŒè¯æ‰€æœ‰å‚æ•°æ˜¯å¦å®Œå…¨åŒ¹é…
                    if existing_job and solvent_model == 'custom' and custom_params:
                        existing_config = existing_job.config.get('solvent_config', {}) if existing_job.config else {}
                        # æ£€æŸ¥æ‰€æœ‰å…³é”®å‚æ•°æ˜¯å¦åŒ¹é…
                        key_params = ['eps', 'eps_inf', 'hbond_acidity', 'hbond_basicity', 'surface_tension']
                        params_match = True
                        for key in key_params:
                            if custom_params.get(key) != existing_config.get(key):
                                params_match = False
                                break
                        if not params_match:
                            existing_job = None  # å‚æ•°ä¸å®Œå…¨åŒ¹é…ï¼Œä¸å¤ç”¨

                    if existing_job:
                        # å¦‚æœæ‰¾åˆ°å·²å®Œæˆçš„ä»»åŠ¡ï¼ŒéªŒè¯åå¤ç”¨ç»“æœ
                        if existing_job.status == QCJobStatus.COMPLETED:
                            from app.utils.qc_reuse import validate_job_for_reuse, copy_result_for_reused_job

                            is_valid, root_job, reason = validate_job_for_reuse(db, existing_job)
                            if not is_valid:
                                logger.warning(f"ä»»åŠ¡ {existing_job.id} ä¸å¯å¤ç”¨: {reason}ï¼Œå°†åˆ›å»ºæ–°ä»»åŠ¡")
                                existing_job = None  # æ¸…ç©ºï¼Œèµ°æ–°å»ºæµç¨‹
                            else:
                                source_job = root_job if root_job else existing_job
                                logger.info(f"Reusing completed QC job {source_job.id} for '{mol_name}' "
                                           f"(smiles: {smiles[:30]}..., functional: {functional}, basis: {basis_set})")
                                # åˆ›å»ºä¸€ä¸ªå¤ç”¨ä»»åŠ¡ï¼Œç›´æ¥æ ‡è®°ä¸ºå·²å®Œæˆ
                                qc_job = QCJob(
                                    user_id=user.id,
                                    md_job_id=md_job.id,
                                    molecule_name=job_mol_name,
                                    smiles=smiles,
                                    molecule_type=mol_type,
                                    basis_set=params["basis_set"],
                                    functional=params["functional"],
                                    charge=charge,
                                    spin_multiplicity=spin_multiplicity,
                                    solvent_model=params["solvent_model"],
                                    solvent_name=params["solvent_name"] if params["solvent_model"] != "gas" else None,
                                    status=QCJobStatus.COMPLETED,
                                    is_reused=True,
                                    reused_from_job_id=source_job.id,  # ç›´æ¥æŒ‡å‘æ ¹ä»»åŠ¡
                                    config={
                                        "accuracy_level": getattr(qc_options, 'accuracy_level', 'standard'),
                                        "solvent_model": params["solvent_model"],
                                        "solvent_name": params["solvent_name"] if params["solvent_model"] != "gas" else None,
                                        "solvent_config": solvent_config,
                                        "recommendation_reason": params["recommendation_reason"],
                                        "auto_params": getattr(qc_options, 'use_recommended_params', True),
                                        "reused_from": source_job.id,
                                    }
                                )
                                db.add(qc_job)
                                db.flush()  # è·å– qc_job.id

                                # ã€å…³é”®ä¿®å¤ã€‘å¤åˆ¶èƒ½é‡ç»“æœåˆ°æ–°ä»»åŠ¡
                                copy_result_for_reused_job(db, source_job, qc_job)

                                db.commit()
                                db.refresh(qc_job)
                                continue  # è·³è¿‡åˆ›å»ºæ–°ä»»åŠ¡

                        if existing_job and existing_job.status != QCJobStatus.COMPLETED:
                            # å­˜åœ¨ç›¸åŒå‚æ•°çš„ä»»åŠ¡ä½†æœªå®Œæˆï¼Œè·³è¿‡åˆ›å»º
                            logger.info(f"Skipping duplicate QC job for '{mol_name}' "
                                       f"(existing job {existing_job.id} status: {existing_job.status})")
                            continue
                    # ======== æŸ¥é‡é€»è¾‘ç»“æŸ ========

                    # åˆ›å»ºQCä»»åŠ¡ï¼ˆæ‰€æœ‰å‚æ•°å­˜å‚¨åœ¨configä¸­ï¼‰
                    logger.info(f"ğŸ“ åˆ›å»ºQCä»»åŠ¡: {job_mol_name}, charge={charge}, spin_multiplicity={spin_multiplicity}")
                    qc_job = QCJob(
                        user_id=user.id,
                        md_job_id=md_job.id,
                        molecule_name=job_mol_name,
                        smiles=smiles,
                        molecule_type=mol_type,
                        basis_set=params["basis_set"],
                        functional=params["functional"],
                        charge=charge,
                        spin_multiplicity=spin_multiplicity,
                        solvent_model=params["solvent_model"],  # âœ… æ·»åŠ æº¶å‰‚æ¨¡å‹å­—æ®µ
                        solvent_name=params["solvent_name"] if params["solvent_model"] != "gas" else None,  # âœ… æ·»åŠ æº¶å‰‚åç§°å­—æ®µ
                        status=QCJobStatus.CREATED,
                        config={
                            "accuracy_level": getattr(qc_options, 'accuracy_level', 'standard'),
                            "solvent_model": params["solvent_model"],
                            "solvent_name": params["solvent_name"] if params["solvent_model"] != "gas" else None,
                            "solvent_config": solvent_config,
                            "recommendation_reason": params["recommendation_reason"],
                            "auto_params": getattr(qc_options, 'use_recommended_params', True),
                        }
                    )

                    db.add(qc_job)
                    db.commit()
                    db.refresh(qc_job)
                    logger.info(f"âœ… QCä»»åŠ¡å·²ä¿å­˜åˆ°æ•°æ®åº“: ID={qc_job.id}, spin_multiplicity={qc_job.spin_multiplicity}")

                    logger.info(f"Created QC job {qc_job.id} for '{job_mol_name}' (type: {mol_type}, "
                               f"charge: {charge}, spin: {spin_multiplicity}, "
                               f"functional: {functional}, basis: {basis_set}, "
                               f"solvent: {solvent_model}/{solvent_name or 'N/A'})")

                    # æ··åˆäº‘æ¨¡å¼ï¼šQCä»»åŠ¡ç”± polling_worker è½®è¯¢è·å–ï¼Œä¸éœ€è¦ Celery
                    # ä»»åŠ¡åˆ›å»ºåçŠ¶æ€ä¸º CREATEDï¼ŒWorker ä¼šè‡ªåŠ¨æ‹‰å–å¹¶æ‰§è¡Œ


@router.get("/quota/check")
def check_job_quota(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Check user's daily job creation quota

    Returns:
        dict: {
            "can_create": bool,
            "current_count": int,
            "limit": int,
            "remaining": int
        }
    """
    can_create, current_count, limit = check_daily_job_limit(db, current_user.id, current_user.role)

    return {
        "can_create": can_create,
        "current_count": current_count,
        "limit": limit,
        "remaining": limit - current_count
    }


@router.get("/", response_model=List[MDJobSchema])
def list_md_jobs(
    system_id: int = None,
    status_filter: JobStatus = None,
    skip: int = 0,
    limit: int = 100,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    List MD jobs

    Args:
        system_id: Filter by system ID
        status_filter: Filter by job status
        skip: Number of records to skip
        limit: Maximum number of records to return
        db: Database session
        current_user: Current authenticated user

    Returns:
        List[MDJob]: List of MD jobs (with user info for admins)
    """
    from sqlalchemy.orm import joinedload, noload
    from app.utils.permissions import require_module_access, MODULE_MD

    # Check module access
    require_module_access(current_user, MODULE_MD)

    # ç®¡ç†å‘˜å¯ä»¥çœ‹åˆ°æ‰€æœ‰ä»»åŠ¡ï¼Œæ™®é€šç”¨æˆ·åªèƒ½çœ‹åˆ°è‡ªå·±çš„ä»»åŠ¡
    if current_user.role == UserRole.ADMIN:
        # ç®¡ç†å‘˜ï¼šä½¿ç”¨ join æŸ¥è¯¢ï¼Œè·å–ç”¨æˆ·ä¿¡æ¯
        query = db.query(MDJob, User).join(User, MDJob.user_id == User.id).options(
            noload('*')  # ç¦ç”¨æ‰€æœ‰å…³è”åŠ è½½ï¼Œé¿å… N+1 æŸ¥è¯¢
        )
    else:
        # æ™®é€šç”¨æˆ·ï¼šåªæŸ¥è¯¢è‡ªå·±çš„ä»»åŠ¡ï¼Œç¦ç”¨å…³è”åŠ è½½
        query = db.query(MDJob).filter(MDJob.user_id == current_user.id).options(
            noload('*')  # ç¦ç”¨æ‰€æœ‰å…³è”åŠ è½½
        )

    # Filter by system if specified
    if system_id:
        query = query.filter(MDJob.system_id == system_id)
    
    # Filter by status if specified
    if status_filter:
        query = query.filter(MDJob.status == status_filter)

    # Order by creation time (newest first)
    query = query.order_by(MDJob.created_at.desc())

    # æ‰§è¡ŒæŸ¥è¯¢
    results = query.offset(skip).limit(limit).all()

    # ä¸ºç®¡ç†å‘˜æ·»åŠ ç”¨æˆ·ä¿¡æ¯
    if current_user.role == UserRole.ADMIN:
        # results æ˜¯ (MDJob, User) å…ƒç»„åˆ—è¡¨
        job_list = []
        for job, user in results:
            job_dict = {
                "id": job.id,
                "system_id": job.system_id,
                "user_id": job.user_id,
                "status": job.status,
                "slurm_job_id": job.slurm_job_id,
                "progress": job.progress,
                "work_dir": job.work_dir,
                "log_file": job.log_file,
                "error_message": job.error_message,
                "config": job.config,
                "created_at": job.created_at,
                "updated_at": job.updated_at,
                "started_at": job.started_at,
                "finished_at": job.finished_at,
                # è®¡è´¹ç›¸å…³å­—æ®µ
                "cpu_cores": job.cpu_cores or 1,
                "estimated_cpu_hours": job.estimated_cpu_hours or 0.0,
                "actual_cpu_hours": job.actual_cpu_hours or 0.0,
                "resp_cpu_hours": job.resp_cpu_hours or 0.0,
                "result_locked": job.result_locked or False,
                "locked_reason": job.locked_reason,
                "billed": job.billed or False,
                "is_free_quota": job.is_free_quota if hasattr(job, 'is_free_quota') else True,
                # æ·»åŠ ç”¨æˆ·ä¿¡æ¯ï¼ˆä»…ç®¡ç†å‘˜å¯è§ï¼‰
                "username": user.username,
                "user_email": user.email,
            }
            job_list.append(job_dict)
        return job_list

    # æ™®é€šç”¨æˆ·ï¼šæ„å»ºåŒ…å«è®¡è´¹ç›¸å…³å­—æ®µçš„ä»»åŠ¡å­—å…¸åˆ—è¡¨
    job_list = []
    for job in results:
        job_dict = {
            "id": job.id,
            "system_id": job.system_id,
            "user_id": job.user_id,
            "status": job.status,
            "slurm_job_id": job.slurm_job_id,
            "progress": job.progress,
            "work_dir": job.work_dir,
            "log_file": job.log_file,
            "error_message": job.error_message,
            "config": job.config,
            "created_at": job.created_at,
            "updated_at": job.updated_at,
            "started_at": job.started_at,
            "finished_at": job.finished_at,
            # è®¡è´¹ç›¸å…³å­—æ®µ
            "cpu_cores": job.cpu_cores or 1,
            "estimated_cpu_hours": job.estimated_cpu_hours or 0.0,
            "actual_cpu_hours": job.actual_cpu_hours or 0.0,
            "resp_cpu_hours": job.resp_cpu_hours or 0.0,
            "result_locked": job.result_locked or False,
            "locked_reason": job.locked_reason,
            "billed": job.billed or False,
            "is_free_quota": job.is_free_quota if hasattr(job, 'is_free_quota') else True,
        }
        job_list.append(job_dict)
    return job_list


@router.get("/{job_id}", response_model=MDJobSchema)
def get_md_job(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Get MD job by ID

    Args:
        job_id: MD job ID
        db: Database session
        current_user: Current authenticated user

    Returns:
        MDJob: MD job data

    Raises:
        HTTPException: If not found or no permission
    """
    from datetime import datetime
    from app.utils.permissions import require_module_access, MODULE_MD

    try:
        job = db.query(MDJob).filter(MDJob.id == job_id).first()

        if not job:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="MD job not found"
            )

        # Check module access (only for owner, not for public data viewers)
        is_owner = job.user_id == current_user.id
        if is_owner:
            require_module_access(current_user, MODULE_MD)

        # Check permission
        # å…è®¸è®¿é—®ï¼š1. è‡ªå·±çš„æ•°æ® 2. ç®¡ç†å‘˜ 3. å…¬å¼€æ•°æ® 4. å·²è¿‡å»¶æœŸçš„æ•°æ®
        is_owner = job.user_id == current_user.id
        is_admin = current_user.role == UserRole.ADMIN
        is_public = job.visibility == DataVisibility.PUBLIC

        # Handle timezone-aware datetime comparison
        is_delayed_expired = False
        if job.visibility == DataVisibility.DELAYED and job.visibility_delay_until:
            from datetime import timezone
            # Get current UTC time with timezone info
            now_utc = datetime.now(timezone.utc)
            # Convert job.visibility_delay_until to UTC if it has timezone info
            delay_until = job.visibility_delay_until
            if delay_until.tzinfo is None:
                # If naive, assume UTC
                delay_until = delay_until.replace(tzinfo=timezone.utc)
            is_delayed_expired = delay_until <= now_utc

        if not (is_owner or is_admin or is_public or is_delayed_expired):
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="Not enough permissions"
            )

        # Validate schema before returning
        try:
            schema = MDJobSchema.model_validate(job)
            return schema
        except Exception as schema_error:
            logger.error(f"Schema validation error for job {job_id}: {str(schema_error)}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Schema validation error: {str(schema_error)}"
            )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting MD job {job_id}: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error getting MD job: {str(e)}"
        )


@router.get("/{job_id}/qc-jobs")
def get_md_job_qc_jobs(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–MDä»»åŠ¡å…³è”çš„æ‰€æœ‰QCä»»åŠ¡åŠçŠ¶æ€æ±‡æ€»

    Args:
        job_id: MDä»»åŠ¡ID
        db: æ•°æ®åº“ä¼šè¯
        current_user: å½“å‰ç”¨æˆ·

    Returns:
        QCä»»åŠ¡åˆ—è¡¨å’ŒçŠ¶æ€æ±‡æ€»
    """
    from datetime import datetime
    from app.schemas.job import QCJobSummary, QCJobsStatusSummary, QCResultSummary
    from app.models.qc import QCResult

    # è·å–MDä»»åŠ¡
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="MD job not found"
        )

    # æ£€æŸ¥æƒé™ï¼ˆæ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼‰
    is_owner = job.user_id == current_user.id
    is_admin = current_user.role == UserRole.ADMIN
    is_public = job.visibility == DataVisibility.PUBLIC
    is_delayed_expired = (
        job.visibility == DataVisibility.DELAYED and
        job.visibility_delay_until and
        job.visibility_delay_until <= datetime.utcnow()
    )

    if not (is_owner or is_admin or is_public or is_delayed_expired):
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Not enough permissions"
        )

    # è·å–å…³è”çš„QCä»»åŠ¡
    qc_jobs = db.query(QCJob).filter(QCJob.md_job_id == job_id).order_by(QCJob.created_at).all()

    # ç»Ÿè®¡çŠ¶æ€
    status_summary = QCJobsStatusSummary(total=len(qc_jobs))
    for qc_job in qc_jobs:
        status_str = qc_job.status.value if hasattr(qc_job.status, 'value') else str(qc_job.status)
        if status_str == "CREATED":
            status_summary.created += 1
        elif status_str == "QUEUED":
            status_summary.queued += 1
        elif status_str == "RUNNING":
            status_summary.running += 1
        elif status_str == "POSTPROCESSING":
            status_summary.postprocessing += 1
        elif status_str == "COMPLETED":
            status_summary.completed += 1
        elif status_str == "FAILED":
            status_summary.failed += 1
        elif status_str == "CANCELLED":
            status_summary.cancelled += 1

    # è·å–æ‰€æœ‰å·²å®ŒæˆQCä»»åŠ¡çš„ç»“æœ
    qc_job_ids = [qc.id for qc in qc_jobs]
    qc_results = {}
    if qc_job_ids:
        results = db.query(QCResult).filter(QCResult.qc_job_id.in_(qc_job_ids)).all()
        for result in results:
            qc_results[result.qc_job_id] = result

    # è½¬æ¢ä¸ºSchema
    qc_jobs_data = []
    for qc in qc_jobs:
        # è·å–è¯¥ä»»åŠ¡çš„ç»“æœ
        result_summary = None
        if qc.id in qc_results:
            r = qc_results[qc.id]
            result_summary = QCResultSummary(
                energy_au=r.energy_au,
                homo_ev=r.homo * 27.2114 if r.homo is not None else None,  # Hartree to eV
                lumo_ev=r.lumo * 27.2114 if r.lumo is not None else None,  # Hartree to eV
                homo_lumo_gap=r.homo_lumo_gap,
                esp_min_kcal=r.esp_min_kcal,
                esp_max_kcal=r.esp_max_kcal,
                dipole_moment=r.dipole_moment,
                has_esp_image=bool(r.esp_image_path or r.esp_image_content),
                has_homo_image=bool(r.homo_image_path or r.homo_image_content),
                has_lumo_image=bool(r.lumo_image_path or r.lumo_image_content),
            )

        qc_jobs_data.append(QCJobSummary(
            id=qc.id,
            molecule_name=qc.molecule_name,
            smiles=qc.smiles,
            molecule_type=qc.molecule_type or "custom",
            status=qc.status.value if hasattr(qc.status, 'value') else str(qc.status),
            progress=qc.progress or 0.0,
            basis_set=qc.basis_set,
            functional=qc.functional or "B3LYP",
            charge=qc.charge if hasattr(qc, 'charge') and qc.charge is not None else 0,
            spin_multiplicity=qc.spin_multiplicity if hasattr(qc, 'spin_multiplicity') and qc.spin_multiplicity is not None else 1,
            solvent_model=qc.solvent_model if hasattr(qc, 'solvent_model') else None,
            solvent_name=qc.solvent_name if hasattr(qc, 'solvent_name') else None,
            accuracy_level=qc.accuracy_level if hasattr(qc, 'accuracy_level') else None,
            is_reused=qc.is_reused if hasattr(qc, 'is_reused') and qc.is_reused else False,
            reused_from_job_id=qc.reused_from_job_id if hasattr(qc, 'reused_from_job_id') else None,
            slurm_job_id=qc.slurm_job_id,
            work_dir=qc.work_dir,
            created_at=qc.created_at,
            started_at=qc.started_at,
            finished_at=qc.finished_at,
            error_message=qc.error_message,
            result=result_summary
        ))

    return {
        "md_job_id": job_id,
        "qc_jobs": qc_jobs_data,
        "status_summary": status_summary,
        "qc_enabled": len(qc_jobs) > 0
    }


@router.put("/{job_id}", response_model=MDJobSchema)
def update_md_job(
    job_id: int,
    job_update: MDJobUpdate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Update MD job

    Args:
        job_id: MD job ID
        job_update: MD job update data
        db: Database session
        current_user: Current authenticated user
        
    Returns:
        MDJob: Updated MD job
        
    Raises:
        HTTPException: If not found or no permission
    """
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    
    if not job:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="MD job not found"
        )
    
    # Check permission (only owner or admin can update)
    check_job_permission(job, current_user)
    
    # Update fields
    update_data = job_update.model_dump(exclude_unset=True)
    for field, value in update_data.items():
        setattr(job, field, value)
    
    db.commit()
    db.refresh(job)
    
    logger.info(f"MD job updated: ID={job.id}")
    return job


@router.put("/{job_id}/config", response_model=MDJobSchema)
def update_md_job_config(
    job_id: int,
    config: Dict[str, Any],
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Update MD job configuration

    Args:
        job_id: MD job ID
        config: Configuration data
        db: Database session
        current_user: Current authenticated user

    Returns:
        MDJob: Updated MD job

    Raises:
        HTTPException: If not found, no permission, or job already submitted
    """
    job = db.query(MDJob).filter(MDJob.id == job_id).first()

    if not job:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="MD job not found"
        )

    # Check permission
    if job.user_id != current_user.id and current_user.role != UserRole.ADMIN:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Not enough permissions"
        )

    # Allow updating config for CREATED, FAILED, CANCELLED, and COMPLETED jobs
    # (for resubmission purposes)
    allowed_statuses = [JobStatus.CREATED, JobStatus.FAILED, JobStatus.CANCELLED, JobStatus.COMPLETED]
    if job.status not in allowed_statuses:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Cannot update config for jobs in {job.status} status. Only CREATED, FAILED, CANCELLED, or COMPLETED jobs can be updated."
        )

    # Update config
    job.config = config
    db.commit()
    db.refresh(job)

    logger.info(f"MD job config updated: ID={job.id}, Status={job.status}")
    return job


@router.post("/{job_id}/submit", response_model=MDJobSchema)
def submit_md_job(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Submit MD job - åœ¨æ··åˆäº‘æ¶æ„ä¸‹ï¼Œåªæ›´æ–°çŠ¶æ€ä¸º CREATEDï¼Œç­‰å¾… Worker æ‹‰å–æ‰§è¡Œ

    Args:
        job_id: MD job ID
        db: Database session
        current_user: Current authenticated user

    Returns:
        MDJob: Updated MD job

    Raises:
        HTTPException: If not found, no permission, or job already submitted
    """
    # Phase 2: ä½¿ç”¨æ–°çš„ QuotaService æ£€æŸ¥é…é¢
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰è¶³å¤Ÿçš„é…é¢
    has_quota, quota_msg = QuotaService.check_quota(current_user, 1.0, db)
    if not has_quota:
        raise HTTPException(
            status_code=status.HTTP_402_PAYMENT_REQUIRED,
            detail=quota_msg
        )

    job = db.query(MDJob).filter(MDJob.id == job_id).first()

    if not job:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="MD job not found"
        )

    # Check permission
    if job.user_id != current_user.id and current_user.role != UserRole.ADMIN:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Not enough permissions"
        )

    # Allow submitting CREATED, CANCELLED, or FAILED jobs
    # CANCELLED/FAILED jobs can be reconfigured and resubmitted
    if job.status not in [JobStatus.CREATED, JobStatus.CANCELLED, JobStatus.FAILED]:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Cannot submit job with status {job.status}. Only CREATED, CANCELLED, or FAILED jobs can be submitted."
        )

    # Get electrolyte system
    electrolyte = db.query(ElectrolyteSystem).filter(
        ElectrolyteSystem.id == job.system_id
    ).first()

    if not electrolyte:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Electrolyte system not found"
        )

    try:
        # å¦‚æœå¯ç”¨äº†QCè®¡ç®—ä½†è¿˜æ²¡æœ‰åˆ›å»ºQCä»»åŠ¡ï¼Œç°åœ¨åˆ›å»º
        if job.config and job.config.get("qc_enabled"):
            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰QCä»»åŠ¡
            existing_qc_jobs = db.query(QCJob).filter(QCJob.md_job_id == job.id).count()
            if existing_qc_jobs == 0:
                logger.info(f"Creating QC jobs for MD job {job.id} on submit...")
                # æ„é€ QCé€‰é¡¹
                from app.schemas.job import MDJobQCOptions
                qc_options = MDJobQCOptions(
                    enabled=True,
                    basis_set=job.config.get("qc_basis_set", "6-31++g(d,p)"),
                    functional=job.config.get("qc_functional", "B3LYP"),
                    molecules=None
                )
                try:
                    _create_qc_jobs_for_md(db, job, electrolyte, current_user, qc_options)
                    logger.info(f"QC jobs created for MD job {job.id}")
                except Exception as qc_error:
                    logger.error(f"Failed to create QC jobs for MD job {job.id}: {qc_error}", exc_info=True)
                    # QCä»»åŠ¡åˆ›å»ºå¤±è´¥ä¸å½±å“MDä»»åŠ¡æäº¤

        # Phase 2: ä½¿ç”¨æ–°çš„ QuotaService æ¶ˆè´¹é…é¢
        # æ¶ˆè´¹ç”¨æˆ·é…é¢ï¼ˆä¼°è®¡çš„æ ¸æ—¶ï¼‰
        # ä½¿ç”¨é¢„ä¼°çš„æ ¸æ—¶è¿›è¡Œå†»ç»“ï¼Œå®é™…æ¶ˆè´¹åœ¨ä»»åŠ¡å®Œæˆæ—¶æ›´æ–°
        estimated_cpu_hours = job.estimated_cpu_hours if hasattr(job, 'estimated_cpu_hours') and job.estimated_cpu_hours else 1.0
        success, message = QuotaService.consume_quota(
            current_user,
            estimated_cpu_hours,
            db,
            reason="MD job submission",
            job_id=job.id
        )
        if not success:
            raise HTTPException(
                status_code=status.HTTP_402_PAYMENT_REQUIRED,
                detail=f"Failed to consume quota: {message}"
            )

        # æ›´æ–°çŠ¶æ€ä¸º SUBMITTEDï¼Œç­‰å¾… Worker æ‹‰å–æ‰§è¡Œ
        job.status = JobStatus.SUBMITTED
        job.error_message = None
        if job.config is None:
            job.config = {}
        job.config["submitted_at"] = datetime.now().isoformat()
        job.config["submitted_by"] = current_user.username
        job.config["quota_consumed"] = estimated_cpu_hours

        # æ›´æ–°ç”¨æˆ·ä½¿ç”¨ç»Ÿè®¡
        from app.models.user_stats import UserUsageStats
        from datetime import date

        today = date.today()
        stats = db.query(UserUsageStats).filter(
            UserUsageStats.user_id == current_user.id,
            UserUsageStats.date == today
        ).first()

        if not stats:
            stats = UserUsageStats(
                user_id=current_user.id,
                date=today,
                jobs_submitted=0,
                jobs_completed=0,
                jobs_failed=0,
                jobs_cancelled=0,
                cpu_hours_used=0.0,
                cluster_analysis_cpu_hours=0.0,
                cluster_analysis_task_count=0,
                storage_used_gb=0.0,
                max_concurrent_jobs=0
            )
            db.add(stats)

        # æ›´æ–°æäº¤è®¡æ•°
        stats.jobs_submitted += 1

        db.commit()
        db.refresh(job)

        logger.info(f"MD job {job.id} submitted by {current_user.username}, status=SUBMITTED, waiting for Worker")

        # åŒæ—¶æäº¤å…³è”çš„ QC ä»»åŠ¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if job.config and job.config.get("qc_enabled"):
            qc_jobs = db.query(QCJob).filter(
                QCJob.md_job_id == job.id,
                QCJob.status == QCJobStatus.CREATED
            ).all()

            if qc_jobs:
                for qc_job in qc_jobs:
                    qc_job.status = QCJobStatus.SUBMITTED
                    qc_job.config = qc_job.config or {}
                    qc_job.config["submitted_at"] = datetime.now().isoformat()
                    qc_job.config["submitted_by"] = current_user.username
                db.commit()
                logger.info(f"Auto-submitted {len(qc_jobs)} QC jobs for MD job {job.id}")

        return job

    except Exception as e:
        logger.error(f"Failed to submit job {job.id}: {e}", exc_info=True)

        # Update job status to FAILED
        job.status = JobStatus.FAILED

        if job.config is None:
            job.config = {}

        job.config["error"] = str(e)

        db.commit()
        db.refresh(job)

        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to submit job: {str(e)}"
        )


@router.post("/{job_id}/cancel", response_model=MDJobSchema)
def cancel_md_job(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Cancel a running or queued MD job

    åœ¨æ··åˆäº‘æ¶æ„ä¸‹ï¼Œæ­¤æ¥å£å°†ä»»åŠ¡çŠ¶æ€è®¾ç½®ä¸º CANCELLINGï¼Œ
    ç”±æ ¡å›­ç½‘ Worker æ£€æµ‹åˆ°åæ‰§è¡Œ scancel å¹¶æ›´æ–°çŠ¶æ€ã€‚

    Args:
        job_id: MD job ID
        db: Database session
        current_user: Current authenticated user

    Returns:
        MDJob: Updated MD job

    Raises:
        HTTPException: If not found, no permission, or job cannot be cancelled
    """
    job = db.query(MDJob).filter(MDJob.id == job_id).first()

    if not job:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="MD job not found"
        )

    # Check permission
    if job.user_id != current_user.id and current_user.role != UserRole.ADMIN:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Not enough permissions"
        )

    # Only allow cancelling CREATED, QUEUED or RUNNING jobs
    if job.status not in [JobStatus.CREATED, JobStatus.QUEUED, JobStatus.RUNNING]:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Cannot cancel job with status {job.status}. Only CREATED, QUEUED or RUNNING jobs can be cancelled."
        )

    # Get Slurm job ID
    slurm_job_id = job.slurm_job_id

    # åœ¨æ··åˆäº‘æ¶æ„ä¸‹ï¼Œç›´æ¥æ›´æ–°æ•°æ®åº“çŠ¶æ€
    # Worker ä¼šæ£€æµ‹åˆ°å–æ¶ˆè¯·æ±‚å¹¶æ‰§è¡Œ scancelï¼ˆå¦‚æœæœ‰ slurm_job_idï¼‰
    logger.info(f"Cancelling job {job_id} (Slurm ID: {slurm_job_id})")

    # Update job status
    job.status = JobStatus.CANCELLED
    job.error_message = f"Cancelled by user {current_user.username}"

    # Update config with cancellation info (use copy to ensure SQLAlchemy detects change)
    config = dict(job.config) if job.config else {}
    config["cancelled_by"] = current_user.username
    config["cancelled_at"] = datetime.now().isoformat()
    config["cancel_slurm_job_id"] = slurm_job_id  # Worker çœ‹åˆ°è¿™ä¸ªä¼šæ‰§è¡Œ scancel
    job.config = config

    try:
        db.commit()
        db.refresh(job)
        logger.info(f"Job {job_id} (Slurm ID: {slurm_job_id}) cancelled by {current_user.username}")
        return job

    except Exception as e:
        logger.error(f"Failed to cancel job {job_id}: {e}")
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to cancel job: {str(e)}"
        )


@router.delete("/{job_id}")
def delete_md_job(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Delete a MD job

    Only allows deleting jobs in CREATED, CANCELLED, COMPLETED, or FAILED status.
    Running or queued jobs must be cancelled first.

    Args:
        job_id: MD job ID
        db: Database session
        current_user: Current authenticated user

    Returns:
        Dict with success message

    Raises:
        HTTPException: If not found, no permission, or job cannot be deleted
    """
    job = db.query(MDJob).filter(MDJob.id == job_id).first()

    if not job:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="MD job not found"
        )

    # Check permission
    check_job_permission(job, current_user)

    # Check if job can be deleted (not running or queued)
    if job.status in [JobStatus.RUNNING, JobStatus.QUEUED]:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Cannot delete running or queued job. Please cancel it first."
        )

    # Delete the job
    db.delete(job)
    db.commit()

    logger.info(f"MD job {job_id} deleted by {current_user.username}")

    return {"message": f"Job {job_id} deleted successfully"}


@router.post("/{job_id}/sync_status")
def sync_job_status(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Sync job status with Slurm

    åœ¨æ··åˆäº‘æ¶æ„ä¸‹ï¼Œæ­¤æ¥å£è¿”å›æ•°æ®åº“ä¸­çš„å½“å‰çŠ¶æ€ã€‚
    å®é™…çš„ Slurm çŠ¶æ€åŒæ­¥ç”±æ ¡å›­ç½‘ Worker é€šè¿‡ /workers/jobs/{job_id}/status API å®Œæˆã€‚
    """
    from app.dependencies import check_job_permission

    # Get job
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ•°æ®éš”ç¦»ï¼šæ£€æŸ¥æƒé™ï¼ˆæ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼‰
    check_job_permission(job, current_user)

    # Get Slurm job ID - check both job.slurm_job_id and job.config
    slurm_job_id = job.slurm_job_id
    if not slurm_job_id and job.config:
        slurm_job_id = job.config.get("slurm_job_id")

    # åœ¨æ··åˆäº‘æ¶æ„ä¸‹ï¼Œè…¾è®¯äº‘åç«¯æ— æ³•ç›´æ¥è®¿é—® Slurm
    # çŠ¶æ€åŒæ­¥ç”± Worker å®šæœŸæ›´æ–°ï¼Œè¿™é‡Œç›´æ¥è¿”å›æ•°æ®åº“ä¸­çš„çŠ¶æ€
    logger.info(f"Sync status for job {job_id}: status={job.status}, slurm_job_id={slurm_job_id}")

    # è¿”å›å½“å‰æ•°æ®åº“ä¸­çš„çŠ¶æ€
    return {
        "job_id": job_id,
        "slurm_job_id": slurm_job_id,
        "slurm_status": job.status.value if job.status else "UNKNOWN",
        "job_status": job.status,
        "progress": job.progress,
        "updated": False,
        "message": "çŠ¶æ€ç”± Worker å®šæœŸåŒæ­¥ï¼Œæ­¤å¤„è¿”å›æ•°æ®åº“å½“å‰çŠ¶æ€"
    }


@router.post("/{job_id}/resubmit", response_model=MDJobSchema)
def resubmit_md_job(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Resubmit a failed or cancelled MD job to cluster

    This endpoint allows resubmitting jobs that have failed or been cancelled.
    It will regenerate the input files and resubmit to Slurm.

    Args:
        job_id: MD job ID
        db: Database session
        current_user: Current authenticated user

    Returns:
        MDJob: Updated MD job

    Raises:
        HTTPException: If not found, no permission, or job cannot be resubmitted
    """
    job = db.query(MDJob).filter(MDJob.id == job_id).first()

    if not job:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="MD job not found"
        )

    # Check permission
    if job.user_id != current_user.id and current_user.role != UserRole.ADMIN:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Not enough permissions"
        )

    # Only allow resubmitting FAILED or CANCELLED jobs
    if job.status not in [JobStatus.FAILED, JobStatus.CANCELLED]:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Cannot resubmit job with status {job.status}. Only FAILED or CANCELLED jobs can be resubmitted."
        )

    # Get electrolyte system
    electrolyte = db.query(ElectrolyteSystem).filter(
        ElectrolyteSystem.id == job.system_id
    ).first()

    if not electrolyte:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Electrolyte system not found"
        )

    try:
        # Clear previous error message
        if job.config is None:
            job.config = {}
        job.config.pop("error", None)
        job.config["resubmitted_at"] = datetime.now().isoformat()
        job.config["resubmitted_by"] = current_user.username

        # Reset job status to SUBMITTED - Worker will pick it up
        job.status = JobStatus.SUBMITTED
        job.error_message = None
        job.progress = 0.0
        job.slurm_job_id = None
        job.started_at = None
        job.finished_at = None
        db.commit()
        db.refresh(job)

        logger.info(f"Job {job.id} resubmitted by {current_user.username}, status=SUBMITTED, waiting for Worker")
        return job

    except Exception as e:
        logger.error(f"Failed to resubmit job {job.id}: {e}")

        # Update job status back to FAILED
        job.status = JobStatus.FAILED

        if job.config is None:
            job.config = {}

        job.config["error"] = str(e)
        job.error_message = str(e)

        db.commit()
        db.refresh(job)

        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to resubmit job: {str(e)}"
        )


@router.get("/{job_id}/atom_mapping")
def get_atom_mapping(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Get atom mapping for a job

    Returns the atom_mapping.json file content
    """
    # Get job
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # Check permission
    if job.user_id != current_user.id and current_user.role != UserRole.ADMIN:
        raise HTTPException(status_code=403, detail="Not authorized to access this job")

    # Get work directory from job
    if job.work_dir:
        work_dir = Path(job.work_dir)
    elif job.config and job.config.get("work_dir"):
        work_dir = Path(job.config.get("work_dir"))
    elif job.config and job.config.get("job_name"):
        # Fallback: construct from job_name
        work_dir = settings.MOLYTE_WORK_BASE_PATH / job.config.get("job_name")
    else:
        raise HTTPException(status_code=404, detail="Work directory not found for this job")

    mapping_file = work_dir / "atom_mapping.json"

    if not mapping_file.exists():
        raise HTTPException(status_code=404, detail="Atom mapping file not found")

    try:
        import json
        with open(mapping_file, 'r') as f:
            mapping = json.load(f)

        return mapping
    except Exception as e:
        logger.error(f"Failed to read atom mapping: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{job_id}/available_labels")
def get_available_labels(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Get available atom labels for RDF calculation

    Returns:
        {
            "all": ["Li_Li", "TEP_P00", ...],
            "by_molecule": {"Li": [...], "TEP": [...]},
            "by_element": {"Li": [...], "O": [...]}
        }
    """
    # Get job
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # Check permission
    if job.user_id != current_user.id and current_user.role != UserRole.ADMIN:
        raise HTTPException(status_code=403, detail="Not authorized to access this job")

    # Get work directory from job
    if job.work_dir:
        work_dir = Path(job.work_dir)
    elif job.config and job.config.get("work_dir"):
        work_dir = Path(job.config.get("work_dir"))
    elif job.config and job.config.get("job_name"):
        # Fallback: construct from job_name
        work_dir = settings.MOLYTE_WORK_BASE_PATH / job.config.get("job_name")
    else:
        raise HTTPException(status_code=404, detail="Work directory not found for this job")

    try:
        from app.workers.rdf_calculator import RDFCalculator

        calculator = RDFCalculator(work_dir)
        labels = calculator.get_available_labels()
        return labels
    except Exception as e:
        logger.error(f"Failed to get available labels: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/{job_id}/calculate_rdf")
def calculate_rdf(
    job_id: int,
    center_label: str,
    target_label: str,
    r_max: float = 10.0,
    n_bins: int = 200,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Calculate RDF between center and target atoms

    Args:
        job_id: Job ID
        center_label: Center atom label (e.g., "Li_Li", "Li_*")
        target_label: Target atom label (e.g., "TEP_O01", "*_O*")
        r_max: Maximum distance (Ã…)
        n_bins: Number of bins

    Returns:
        {
            "r": [0.05, 0.15, ...],
            "g_r": [0.0, 0.1, ...],
            "center_label": "Li_Li",
            "target_label": "TEP_O01",
            "center_atom_count": 50,
            "target_atom_count": 100,
            "frame_count": 100
        }
    """
    # Get job
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # Check permission (æ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼Œæ£€æŸ¥result_locked)
    check_job_permission(job, current_user)

    # Check job status
    if job.status not in [JobStatus.COMPLETED, JobStatus.POSTPROCESSING]:
        raise HTTPException(
            status_code=400,
            detail=f"Job is not completed yet (status: {job.status})"
        )

    # Get work directory from job
    if job.work_dir:
        work_dir = Path(job.work_dir)
    elif job.config and job.config.get("work_dir"):
        work_dir = Path(job.config.get("work_dir"))
    elif job.config and job.config.get("job_name"):
        # Fallback: construct from job_name
        work_dir = settings.MOLYTE_WORK_BASE_PATH / job.config.get("job_name")
    else:
        raise HTTPException(status_code=404, detail="Work directory not found for this job")

    try:
        from app.workers.rdf_calculator import RDFCalculator

        calculator = RDFCalculator(work_dir)
        result = calculator.calculate_rdf(
            center_label=center_label,
            target_label=target_label,
            r_max=r_max,
            n_bins=n_bins
        )

        logger.info(f"Calculated RDF for job {job_id}: {center_label} -> {target_label}")
        return result

    except Exception as e:
        logger.error(f"Failed to calculate RDF: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{job_id}/msd_results")
def get_msd_results(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Get saved MSD results for a job

    Returns:
        List of MSD results with diffusion coefficients
    """
    from app.models.result import MSDResult
    from app.dependencies import check_job_permission

    # Get job
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ•°æ®éš”ç¦»ï¼šæ£€æŸ¥æƒé™ï¼ˆæ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼‰
    check_job_permission(job, current_user)

    # Get MSD results directly from database
    results = db.query(MSDResult).filter(MSDResult.md_job_id == job_id).all()

    return [
        {
            'id': r.id,
            'species': r.species,
            'time': r.t_values,
            'msd_x': r.msd_x_values,
            'msd_y': r.msd_y_values,
            'msd_z': r.msd_z_values,
            'msd_total': r.msd_total_values,
            'labels': r.labels,
            'diffusion_coefficient': r.diffusion_coefficient,
            'ionic_conductivity': r.ionic_conductivity,
            'mobility': r.mobility,
            'charge': r.charge,
            'created_at': r.created_at.isoformat() if r.created_at else None,
        }
        for r in results
    ]


@router.post("/{job_id}/calculate_msd")
def calculate_msd(
    job_id: int,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Calculate MSD for a completed job

    Returns:
        Message indicating MSD calculation started
    """
    from app.tasks.msd_processor import process_msd_data
    from pathlib import Path

    # Get job
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # Check permission (æ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼Œæ£€æŸ¥result_locked)
    check_job_permission(job, current_user)

    # Check job status
    if job.status != JobStatus.COMPLETED:
        raise HTTPException(status_code=400, detail="Job must be completed before calculating MSD")

    # Check work directory
    if not job.work_dir or not Path(job.work_dir).exists():
        raise HTTPException(status_code=400, detail="Work directory not found")

    try:
        # è·å–ä»»åŠ¡é…ç½®ä¸­çš„æ¸©åº¦ã€ç›’å­ä½“ç§¯å’Œç¦»å­æ•°é‡
        temperature = 298.15  # é»˜è®¤æ¸©åº¦
        box_volume = None
        ion_counts = None

        if job.config:
            # ä»é…ç½®ä¸­è·å–æ¸©åº¦
            if 'temperature' in job.config:
                temperature = float(job.config['temperature'])

            # ä»é…ç½®ä¸­è·å–ç›’å­ä½“ç§¯
            if 'box_volume' in job.config:
                box_volume = float(job.config['box_volume'])

            # ä»é…ç½®ä¸­è·å–ç¦»å­æ•°é‡
            if 'ion_counts' in job.config:
                ion_counts = job.config['ion_counts']
            elif 'electrolyte' in job.config:
                # å°è¯•ä»ç”µè§£è´¨é…ç½®ä¸­æå–ç¦»å­æ•°é‡
                electrolyte = job.config['electrolyte']
                ion_counts = {}
                if 'cation' in electrolyte and 'cation_count' in electrolyte:
                    ion_counts[electrolyte['cation']] = electrolyte['cation_count']
                if 'anion' in electrolyte and 'anion_count' in electrolyte:
                    ion_counts[electrolyte['anion']] = electrolyte['anion_count']

        # Process MSD data with temperature, box_volume, and ion_counts
        results = process_msd_data(
            db,
            job_id,
            Path(job.work_dir),
            temperature=temperature,
            box_volume=box_volume,
            ion_counts=ion_counts
        )

        return {
            "message": "MSD calculation completed",
            "num_results": len(results),
            "results": [
                {
                    "species": r.species,
                    "diffusion_coefficient": r.diffusion_coefficient,
                    "ionic_conductivity": r.ionic_conductivity,
                    "mobility": r.mobility,
                    "charge": r.charge,
                }
                for r in results
            ]
        }
    except Exception as e:
        logger.error(f"Failed to calculate MSD: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{job_id}/rdf_results")
def get_rdf_results(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Get saved RDF results for a job

    Returns:
        List of RDF results with analysis data
    """
    from app.models.result import RDFResult
    from app.dependencies import check_job_permission

    # Get job
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ•°æ®éš”ç¦»ï¼šæ£€æŸ¥æƒé™ï¼ˆæ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼‰
    check_job_permission(job, current_user)

    # Get RDF results
    rdf_results = db.query(RDFResult).filter(RDFResult.md_job_id == job_id).all()

    return [
        {
            "id": result.id,
            "center_species": result.center_species,
            "shell_species": result.shell_species,
            "r": result.r_values,
            "g_r": result.g_r_values,
            "coordination_number_values": result.coordination_number_values,  # é…ä½æ•°æ•°ç»„
            "first_peak_position": result.first_peak_position,
            "first_peak_height": result.first_peak_height,
            "coordination_number": result.coordination_number,  # æœ€ç»ˆé…ä½æ•°
            "created_at": result.created_at.isoformat() if result.created_at else None,
        }
        for result in rdf_results
    ]


@router.get("/{job_id}/molecule_templates")
def get_molecule_templates(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    Get molecule templates with 3D structures and charges

    Returns:
        List of molecules with PDB structure and charge information
    """
    from app.dependencies import check_job_permission
    from app.models.result import ResultSummary

    # Get job
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ•°æ®éš”ç¦»ï¼šæ£€æŸ¥æƒé™ï¼ˆæ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼‰
    check_job_permission(job, current_user)

    # ä¼˜å…ˆä»æ•°æ®åº“è¯»å–åˆ†å­ç»“æ„ï¼ˆWorker ä¸Šä¼ çš„ï¼‰
    result_summary = db.query(ResultSummary).filter(
        ResultSummary.md_job_id == job_id
    ).first()

    if result_summary and result_summary.molecule_structures:
        logger.info(f"Returning molecule structures from database for job {job_id}")
        return {"molecules": result_summary.molecule_structures}

    # å›é€€ï¼šä»å·¥ä½œç›®å½•è¯»å–ï¼ˆæœ¬åœ°è¿è¡Œçš„æƒ…å†µï¼‰
    # Get work directory
    if job.work_dir:
        work_dir = Path(job.work_dir)
    elif job.config and job.config.get("work_dir"):
        work_dir = Path(job.config.get("work_dir"))
    elif job.config and job.config.get("job_name"):
        work_dir = settings.MOLYTE_WORK_BASE_PATH / job.config.get("job_name")
    else:
        raise HTTPException(status_code=404, detail="Work directory not found and no molecule structures in database")

    try:
        import re
        molecules = []
        seen_molecules = set()  # ç”¨äºå»é‡

        # è·å–ç”µè·è®¡ç®—æ–¹æ³•
        charge_method = job.config.get("charge_method", "ligpargen") if job.config else "ligpargen"

        # é¦–å…ˆæ‰¾åˆ°æ‰€æœ‰ .lt æ–‡ä»¶ï¼ˆè¿™äº›æ˜¯å®é™…ä½¿ç”¨çš„åˆ†å­ï¼‰
        lt_files = list(work_dir.glob("*.lt"))

        # è·å–ä»»åŠ¡åç§°ï¼Œç”¨äºè¿‡æ»¤ç³»ç»Ÿçº§åˆ«çš„ .lt æ–‡ä»¶
        job_name = job.config.get("job_name", "") if job.config else ""

        for lt_file in lt_files:
            base_name = lt_file.stem  # ä¾‹å¦‚ "Li", "FSI", "EC"

            # è·³è¿‡ç³»ç»Ÿçº§åˆ«çš„ .lt æ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯æ•´ä¸ªä»»åŠ¡åç§°ï¼‰
            if base_name == job_name or len(base_name) > 50:
                logger.info(f"Skipping system-level .lt file: {base_name}")
                continue

            # è·³è¿‡å·²å¤„ç†çš„åˆ†å­
            if base_name in seen_molecules:
                continue
            seen_molecules.add(base_name)

            # æŸ¥æ‰¾å¯¹åº”çš„ PDB æ–‡ä»¶
            # æ ¹æ® molyte_command.py çš„é€»è¾‘ï¼š
            # - æº¶å‰‚åˆ†å­ä½¿ç”¨ .charmm.pdbï¼ˆå› ä¸º RESP ç”µè·è®¡ç®—å’Œ Packmol éƒ½ä½¿ç”¨è¿™ä¸ªæ–‡ä»¶ï¼‰
            # - ç¦»å­ä½¿ç”¨ .pdbï¼ˆä» initial_salts ç›®å½•å¤åˆ¶çš„ï¼‰
            #
            # ä¼˜å…ˆçº§é¡ºåºï¼š
            # 1. {base_name}.charmm.pdb (æº¶å‰‚åˆ†å­ï¼ŒåŒ…å« RESP ç”µè·)
            # 2. {base_name}.q.pdb (LigParGen ç”Ÿæˆçš„ç”µè·æ–‡ä»¶)
            # 3. {base_name}.pdb (ç¦»å­æˆ–å…¶ä»–åˆ†å­)
            pdb_file = None
            pdb_candidates = [
                work_dir / f"{base_name}.charmm.pdb",
                work_dir / f"{base_name}.q.pdb",
                work_dir / f"{base_name}.pdb",
            ]

            for candidate in pdb_candidates:
                if candidate.exists():
                    pdb_file = candidate
                    logger.info(f"Found PDB file for {base_name}: {candidate.name}")
                    break

            if not pdb_file:
                logger.warning(f"PDB file not found for {base_name} in {work_dir}")
                logger.warning(f"Tried: .charmm.pdb, .q.pdb, .pdb")
                continue

            # Read PDB content
            try:
                with open(pdb_file, 'r', encoding='utf-8') as f:
                    pdb_content = f.read()
            except UnicodeDecodeError:
                # Try with latin-1 encoding
                with open(pdb_file, 'r', encoding='latin-1') as f:
                    pdb_content = f.read()

            # Parse atoms from PDB
            atoms = []
            for line in pdb_content.split('\n'):
                # Accept both ATOM and HETATM records
                if line.startswith('ATOM') or line.startswith('HETATM'):
                    atom_id = int(line[6:11].strip())
                    atom_name = line[12:16].strip()
                    x = float(line[30:38].strip())
                    y = float(line[38:46].strip())
                    z = float(line[46:54].strip())
                    element = line[76:78].strip() if len(line) > 76 else atom_name[0]

                    atoms.append({
                        "id": atom_id,
                        "name": atom_name,
                        "element": element,
                        "x": x,
                        "y": y,
                        "z": z,
                        "charge": None  # Will be filled from .lt file
                    })

            # Read charges from .lt file
            with open(lt_file, 'r') as f:
                lt_content = f.read()

            # Extract charges from "In Charges" section or "Data Atoms" section
            charge_map = {}

            # Method 1: Parse from "In Charges" section
            charges_section = re.search(r'write_once\("In Charges"\)\s*\{(.*?)\}', lt_content, re.DOTALL)
            if charges_section:
                for line in charges_section.group(1).split('\n'):
                    match = re.search(r'set type @atom:(\w+)\s+charge\s+([-\d.]+)', line)
                    if match:
                        atom_type = match.group(1)
                        charge = float(match.group(2))
                        charge_map[atom_type] = charge

            # Method 2: Parse from "Data Atoms" section (has charge in 4th column)
            atoms_section = re.search(r'write\("Data Atoms"\)\s*\{(.*?)\}', lt_content, re.DOTALL)
            if atoms_section:
                atom_lines = []
                for line in atoms_section.group(1).split('\n'):
                    line = line.strip()
                    if line and not line.startswith('#'):
                        # Format: $atom:XXX $mol:YYY @atom:ZZZ CHARGE X Y Z
                        match = re.search(r'\$atom:(\w+)\s+\$mol[:\w]*\s+@atom:(\w+)\s+([-\d.]+)\s+([-\d.]+)\s+([-\d.]+)\s+([-\d.]+)', line)
                        if match:
                            atom_id_or_name = match.group(1)
                            atom_type = match.group(2)
                            charge = float(match.group(3))
                            x = float(match.group(4))
                            y = float(match.group(5))
                            z = float(match.group(6))
                            atom_lines.append({
                                'id_or_name': atom_id_or_name,
                                'type': atom_type,
                                'charge': charge,
                                'x': x,
                                'y': y,
                                'z': z
                            })

                # å°è¯•æŒ‰åæ ‡åŒ¹é…åŸå­
                for i, lt_atom in enumerate(atom_lines):
                    # æ–¹æ³•1: æŒ‰åæ ‡åŒ¹é…ï¼ˆå…è®¸å°è¯¯å·®ï¼‰
                    matched = False
                    for pdb_atom in atoms:
                        if (abs(pdb_atom['x'] - lt_atom['x']) < 0.01 and
                            abs(pdb_atom['y'] - lt_atom['y']) < 0.01 and
                            abs(pdb_atom['z'] - lt_atom['z']) < 0.01):
                            pdb_atom['charge'] = lt_atom['charge']
                            matched = True
                            break

                    # æ–¹æ³•2: å¦‚æœåæ ‡ä¸åŒ¹é…ï¼ŒæŒ‰é¡ºåºåŒ¹é…ï¼ˆå‡è®¾ PDB å’Œ LT çš„åŸå­é¡ºåºä¸€è‡´ï¼‰
                    if not matched and i < len(atoms):
                        atoms[i]['charge'] = lt_atom['charge']

            # Apply charge_map to atoms by element type
            for atom in atoms:
                if atom['charge'] is None and atom['element'] in charge_map:
                    atom['charge'] = charge_map[atom['element']]

            # Determine molecule type based on total charge
            total_charge = sum(atom['charge'] for atom in atoms if atom['charge'] is not None)

            if total_charge > 0.5:  # Positive charge -> cation
                mol_type = "cation"
            elif total_charge < -0.5:  # Negative charge -> anion
                mol_type = "anion"
            else:  # Neutral -> solvent
                mol_type = "solvent"

            molecules.append({
                "name": base_name,
                "type": mol_type,
                "pdb_content": pdb_content,
                "atoms": atoms,
                "total_charge": total_charge,
                "charge_method": charge_method
            })

        return {"molecules": molecules}

    except Exception as e:
        logger.error(f"Failed to get molecule templates: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{job_id}/structure_info")
async def get_structure_info(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–è®¡ç®—åçš„ç»“æ„ä¿¡æ¯ï¼ˆå¯†åº¦ã€æµ“åº¦ç­‰ï¼‰
    ä¼˜å…ˆä»æ•°æ®åº“è¯»å–ï¼Œå…¶æ¬¡ä»æ–‡ä»¶è¯»å–
    """
    from app.models.result import ResultSummary
    from app.dependencies import check_job_permission

    # è·å–ä»»åŠ¡
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ•°æ®éš”ç¦»ï¼šæ£€æŸ¥æƒé™ï¼ˆæ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼‰
    check_job_permission(job, current_user)

    try:
        # è·å–ä»»åŠ¡åç§°
        job_name = job.config.get('job_name', f'MD-{job.id}')

        # æ–¹æ³•0: ä¼˜å…ˆä»æ•°æ®åº“è¯»å–
        summary = db.query(ResultSummary).filter(ResultSummary.md_job_id == job_id).first()
        if summary and (summary.final_density or summary.concentration):
            structure_info = {
                "available": True,
                "sample_name": job_name,
                "density": summary.final_density,
                "initial_density": summary.initial_density,
                "concentration": summary.concentration,
                "initial_concentration": summary.initial_concentration,
                "box_dimensions": None,
                "initial_box_dimensions": None,
            }

            # æ ¼å¼åŒ–ç›’å­å°ºå¯¸
            if summary.box_x and summary.box_y and summary.box_z:
                structure_info["box_dimensions"] = f"{summary.box_x:.2f} Ã— {summary.box_y:.2f} Ã— {summary.box_z:.2f}"
            if summary.initial_box_x and summary.initial_box_y and summary.initial_box_z:
                structure_info["initial_box_dimensions"] = f"{summary.initial_box_x:.2f} Ã— {summary.initial_box_y:.2f} Ã— {summary.initial_box_z:.2f}"

            logger.info(f"ä»æ•°æ®åº“è¯»å–ç»“æ„ä¿¡æ¯: job_id={job_id}, density={summary.final_density}")
            return structure_info

        # æ„å»ºå·¥ä½œç›®å½•
        work_dir = Path(job.work_dir) if job.work_dir else None
        if not work_dir or not work_dir.exists():
            return {"available": False, "message": "Work directory not found"}

        structure_info = {
            "available": False,
            "sample_name": job_name,
            "box_dimensions": None,
            "density": None,
            "concentration": None,
            "initial_density": None,
            "initial_concentration": None,
            "initial_box_dimensions": None,
        }

        # æ–¹æ³•1: å°è¯•ä» Excel æ–‡ä»¶è¯»å–
        try:
            import openpyxl
            possible_paths = [
                work_dir / "Results" / job_name / f"structure_{job_name}.xlsx",
                work_dir / f"structure_{job_name}.xlsx",
            ]
            structure_file = None
            for path in possible_paths:
                if path.exists():
                    structure_file = path
                    break

            if structure_file:
                wb = openpyxl.load_workbook(structure_file, data_only=True)
                ws = wb.active
                for row_idx, row in enumerate(ws.iter_rows(min_row=1, max_row=5, values_only=True), 1):
                    if len(row) >= 2:
                        label = str(row[0]) if row[0] else ""
                        value = row[1]
                        if "Sample Name" in label:
                            structure_info["sample_name"] = str(value) if value else None
                        elif "Box Dimensions" in label:
                            structure_info["box_dimensions"] = str(value) if value else None
                        elif "Density" in label:
                            try:
                                structure_info["density"] = float(value) if value else None
                            except (ValueError, TypeError):
                                pass
                        elif "Concentration" in label or "concentration" in label.lower():
                            try:
                                structure_info["concentration"] = float(value) if value else None
                            except (ValueError, TypeError):
                                pass
                if structure_info["density"] is not None:
                    structure_info["available"] = True
        except Exception as e:
            logger.warning(f"Failed to read Excel structure file: {e}")

        # æ–¹æ³•2: å¦‚æœ Excel æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä» LAMMPS log æ–‡ä»¶è¯»å–
        if structure_info["density"] is None:
            log_file = work_dir / f"{job_name}.log"
            if log_file.exists():
                try:
                    with open(log_file, 'r') as f:
                        lines = f.readlines()

                    # è¾…åŠ©å‡½æ•°ï¼šä»ä¸€è¡Œæ•°æ®ä¸­æå–å¯†åº¦å’Œç›’å­å°ºå¯¸
                    # LAMMPS thermo è¾“å‡ºæ ¼å¼: Step CPU CPULeft Temp Density Lx Ly Lz ...
                    # åˆ—ç´¢å¼•:                  0    1   2       3    4       5  6  7
                    def parse_thermo_line(parts):
                        density_val = None
                        box_vals = []
                        try:
                            # æ ¹æ®åˆ—ä½ç½®æå–å¯†åº¦ï¼ˆç¬¬5åˆ—ï¼Œç´¢å¼•4ï¼‰
                            if len(parts) > 4:
                                density_val = float(parts[4])

                            # æ ¹æ®åˆ—ä½ç½®æå–ç›’å­å°ºå¯¸ï¼ˆç¬¬6-8åˆ—ï¼Œç´¢å¼•5-7ï¼‰
                            if len(parts) > 7:
                                box_vals = [float(parts[5]), float(parts[6]), float(parts[7])]
                        except (ValueError, IndexError):
                            # å¦‚æœæŒ‰åˆ—ä½ç½®æå–å¤±è´¥ï¼Œè¿”å› None
                            density_val = None
                            box_vals = []

                        return density_val, box_vals

                    # åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆæ•°æ®è¡Œ
                    skip_prefixes = ('Loop', 'Performance', 'MPI', 'Section',
                                     'Total', 'Pair', 'Bond', 'Kspace', 'Neigh',
                                     'Comm', 'Output', 'Modify', 'Other', 'Nlocal',
                                     'Nghost', 'Neighs', 'Ave', 'Neighbor', 'Dangerous',
                                     'System', 'PPPM', 'WARNING', 'G vector', 'grid',
                                     'stencil', 'estimated', 'using', '3d grid', '-',
                                     'Step', 'Per', 'run', 'thermo', 'fix', 'dump',
                                     'Memory', 'units', 'atom', 'pair', 'kspace',
                                     'Lattice', 'Created', 'Reading', 'Replicate')

                    def is_data_line(line_str):
                        line_str = line_str.strip()
                        if not line_str:
                            return False
                        if line_str.startswith(skip_prefixes):
                            return False
                        parts = line_str.split()
                        if len(parts) < 8:
                            return False
                        try:
                            int(parts[0])  # ç¬¬ä¸€åˆ—åº”è¯¥æ˜¯æ—¶é—´æ­¥ï¼ˆæ•´æ•°ï¼‰
                            return True
                        except ValueError:
                            return False

                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ª "Step" è¡¨å¤´è¡Œçš„ä½ç½®ï¼ˆèƒ½é‡æœ€å°åŒ–é˜¶æ®µçš„å¼€å§‹ï¼Œå³çœŸæ­£çš„åˆå§‹çŠ¶æ€ï¼‰
                    first_step_header_idx = -1
                    for i, line in enumerate(lines):
                        if line.strip().startswith('Step'):
                            first_step_header_idx = i
                            break  # åªæ‰¾ç¬¬ä¸€ä¸ª

                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ª "Step" è¡¨å¤´ä¹‹åçš„ç¬¬ä¸€è¡Œæ•°æ®ï¼ˆçœŸæ­£çš„åˆå§‹çŠ¶æ€ï¼‰
                    first_data_line = None
                    if first_step_header_idx >= 0:
                        for line in lines[first_step_header_idx + 1:]:
                            if is_data_line(line):
                                first_data_line = line.strip().split()
                                break

                    # æ‰¾åˆ°æœ€åä¸€è¡Œæ•°æ®ï¼ˆæœ€ç»ˆçŠ¶æ€ï¼‰
                    last_data_line = None
                    for line in reversed(lines[-300:]):
                        if is_data_line(line):
                            last_data_line = line.strip().split()
                            break

                    # è§£æåˆå§‹çŠ¶æ€
                    if first_data_line:
                        init_density, init_box = parse_thermo_line(first_data_line)
                        if init_density:
                            structure_info["initial_density"] = round(init_density, 4)
                        if len(init_box) >= 3:
                            structure_info["initial_box_dimensions"] = f"{init_box[0]:.2f} Ã— {init_box[1]:.2f} Ã— {init_box[2]:.2f}"

                    # è§£ææœ€ç»ˆçŠ¶æ€
                    if last_data_line:
                        final_density, final_box = parse_thermo_line(last_data_line)
                        if final_density:
                            structure_info["density"] = round(final_density, 4)
                            structure_info["available"] = True
                        if len(final_box) >= 3:
                            structure_info["box_dimensions"] = f"{final_box[0]:.2f} Ã— {final_box[1]:.2f} Ã— {final_box[2]:.2f}"

                        # è®¡ç®—æµ“åº¦ï¼ˆåˆå§‹å’Œæœ€ç»ˆï¼‰
                        try:
                            electrolyte = db.query(ElectrolyteSystem).filter(
                                ElectrolyteSystem.id == job.system_id
                            ).first()

                            if electrolyte:
                                cation_count = sum(c.get('number', 0) for c in (electrolyte.cations or []))
                                avogadro = 6.022e23

                                # è®¡ç®—åˆå§‹æµ“åº¦
                                if init_box and len(init_box) >= 3 and cation_count > 0:
                                    init_volume_L = (init_box[0] * init_box[1] * init_box[2]) * 1e-27
                                    if init_volume_L > 0:
                                        init_conc = (cation_count / avogadro) / init_volume_L
                                        structure_info["initial_concentration"] = round(init_conc, 4)

                                # è®¡ç®—æœ€ç»ˆæµ“åº¦
                                if final_box and len(final_box) >= 3 and cation_count > 0:
                                    final_volume_L = (final_box[0] * final_box[1] * final_box[2]) * 1e-27
                                    if final_volume_L > 0:
                                        final_conc = (cation_count / avogadro) / final_volume_L
                                        structure_info["concentration"] = round(final_conc, 4)
                        except Exception as e:
                            logger.warning(f"Failed to calculate concentration: {e}")

                    logger.info(f"Parsed LAMMPS log for job {job_id}: initial_density={structure_info['initial_density']}, density={structure_info['density']}")

                except Exception as e:
                    logger.warning(f"Failed to parse LAMMPS log file: {e}")
                    import traceback
                    traceback.print_exc()

        if not structure_info["available"]:
            return {"available": False, "message": "Could not extract structure info from job output"}

        logger.info(f"Read structure info for job {job_id}: {structure_info}")
        return structure_info

    except Exception as e:
        logger.error(f"Failed to read structure info: {e}")
        import traceback
        traceback.print_exc()
        return {"available": False, "message": str(e)}


@router.get("/{job_id}/plots/{plot_name}")
async def get_rdf_plot(
    job_id: int,
    plot_name: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å– RDF å›¾è¡¨æ–‡ä»¶

    Args:
        job_id: ä»»åŠ¡ ID
        plot_name: å›¾è¡¨æ–‡ä»¶åï¼ˆå¦‚ rdf_combined.png, rdf_categorized.pngï¼‰

    Returns:
        å›¾è¡¨æ–‡ä»¶
    """
    from fastapi.responses import FileResponse
    from app.dependencies import check_job_permission

    # è·å–ä»»åŠ¡
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ£€æŸ¥æƒé™ï¼ˆæ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼Œæ£€æŸ¥result_lockedï¼‰
    check_job_permission(job, current_user)

    # æ„å»ºå›¾è¡¨æ–‡ä»¶è·¯å¾„
    if not job.work_dir:
        raise HTTPException(status_code=404, detail="Job work directory not found")

    work_dir = Path(job.work_dir)
    plot_file = work_dir / "plots" / plot_name

    if not plot_file.exists():
        raise HTTPException(status_code=404, detail=f"Plot file not found: {plot_name}")

    return FileResponse(
        path=str(plot_file),
        media_type="image/png",
        filename=plot_name
    )


# ============== Slurm çŠ¶æ€æŸ¥è¯¢ API ==============

@router.get("/{job_id}/slurm_status")
def get_job_slurm_status(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–ä»»åŠ¡çš„ Slurm çŠ¶æ€

    åœ¨æ··åˆäº‘æ¶æ„ä¸‹ï¼Œè¿”å›æ•°æ®åº“ä¸­ç”± Worker åŒæ­¥çš„çŠ¶æ€ï¼Œ
    è€Œä¸æ˜¯ç›´æ¥æŸ¥è¯¢ Slurmï¼ˆå› ä¸ºåç«¯æ— æ³•è®¿é—®æ ¡å›­ç½‘ Slurm é›†ç¾¤ï¼‰ã€‚
    """
    from app.dependencies import check_job_permission

    # è·å–ä»»åŠ¡
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ•°æ®éš”ç¦»ï¼šæ£€æŸ¥æƒé™ï¼ˆæ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼‰
    check_job_permission(job, current_user)

    # è·å– Slurm Job ID
    slurm_job_id = job.slurm_job_id or (job.config.get("slurm_job_id") if job.config else None)

    if not slurm_job_id:
        return {
            "job_id": job_id,
            "slurm_job_id": None,
            "status": "NOT_SUBMITTED",
            "message": "ä»»åŠ¡å°šæœªæäº¤åˆ° Slurm",
            "job_status": job.status.value if job.status else None,
        }

    # æ··åˆäº‘æ¶æ„ï¼šä»æ•°æ®åº“è¿”å›ç”± Worker åŒæ­¥çš„çŠ¶æ€
    # æ˜ å°„æ•°æ®åº“çŠ¶æ€åˆ° Slurm çŠ¶æ€æ˜¾ç¤º
    status_mapping = {
        "CREATED": "PENDING",
        "QUEUED": "PENDING",
        "RUNNING": "RUNNING",
        "POSTPROCESSING": "COMPLETING",
        "COMPLETED": "COMPLETED",
        "FAILED": "FAILED",
        "CANCELLED": "CANCELLED",
    }

    db_status = job.status.value if job.status else "UNKNOWN"
    slurm_display_status = status_mapping.get(db_status, db_status)

    return {
        "job_id": job_id,
        "slurm_job_id": slurm_job_id,
        "status": slurm_display_status,
        "raw_state": db_status,
        "exit_code": None,
        "start_time": job.started_at.isoformat() if job.started_at else None,
        "end_time": job.finished_at.isoformat() if job.finished_at else None,
        "elapsed": None,
        "cpu_time": None,
        "job_status": db_status,
        "message": "çŠ¶æ€ç”±æ ¡å›­ç½‘ Worker å®šæœŸåŒæ­¥",
    }


# ============== æº¶å‰‚åŒ–ç»“æ„åˆ†æ API ==============

@router.get("/{job_id}/solvation")
def get_solvation_structures(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–ä»»åŠ¡çš„æº¶å‰‚åŒ–ç»“æ„åˆ†æç»“æœ

    è¿”å›æº¶å‰‚åŒ–ç»“æ„åˆ—è¡¨ï¼ŒåŒ…æ‹¬é…ä½æ•°ã€ç»„æˆã€ç»“æ„æ–‡ä»¶è·¯å¾„ç­‰
    """
    from app.models.result import SolvationStructure
    from app.dependencies import check_job_permission

    # è·å–ä»»åŠ¡
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ•°æ®éš”ç¦»ï¼šæ£€æŸ¥æƒé™ï¼ˆæ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼‰
    check_job_permission(job, current_user)

    # æŸ¥è¯¢æº¶å‰‚åŒ–ç»“æ„
    structures = db.query(SolvationStructure).filter(
        SolvationStructure.md_job_id == job_id
    ).order_by(SolvationStructure.coordination_num.desc()).all()

    return [
        {
            "id": s.id,
            "center_ion": s.center_ion,
            "structure_type": s.structure_type,
            "coordination_num": s.coordination_num,
            "composition": s.composition,
            "mol_order": s.mol_order,  # æ–°å¢ï¼šåˆ†å­é¡ºåºä¿¡æ¯
            "file_path": s.file_path,
            "xyz_content": s.xyz_content,  # æ–°å¢ï¼šç›´æ¥è¿”å› XYZ å†…å®¹
            "snapshot_frame": s.snapshot_frame,
            "description": s.description,
            "created_at": s.created_at.isoformat() if s.created_at else None,
        }
        for s in structures
    ]


@router.post("/{job_id}/trigger_postprocess")
def trigger_postprocess(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    æ‰‹åŠ¨è§¦å‘åå¤„ç†ä»»åŠ¡ï¼ˆRDF åˆ†æã€å›¾è¡¨ç”Ÿæˆç­‰ï¼‰

    Args:
        job_id: ä»»åŠ¡ ID

    Returns:
        Dict with task status
    """
    from app.dependencies import check_resource_permission
    from app.tasks.postprocess import postprocess_md_job_task

    # è·å–ä»»åŠ¡
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ•°æ®éš”ç¦»ï¼šæ£€æŸ¥æƒé™
    check_resource_permission(job.user_id, current_user)

    # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
    if job.status not in [JobStatus.COMPLETED, JobStatus.POSTPROCESSING]:
        raise HTTPException(
            status_code=400,
            detail=f"Job must be COMPLETED to trigger postprocessing. Current status: {job.status}"
        )

    try:
        # è§¦å‘ Celery åå¤„ç†ä»»åŠ¡
        task = postprocess_md_job_task.delay(job_id)

        logger.info(f"Postprocessing task triggered for job {job_id}: task_id={task.id}")

        return {
            "success": True,
            "message": "Postprocessing task triggered",
            "task_id": task.id,
            "job_id": job_id
        }
    except Exception as e:
        logger.error(f"Failed to trigger postprocessing for job {job_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to trigger postprocessing: {str(e)}"
        )


@router.post("/{job_id}/solvation/refresh")
def refresh_solvation_structures(
    job_id: int,
    cutoff: float = 3.0,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    é‡æ–°è®¡ç®—/åˆ·æ–°æº¶å‰‚åŒ–ç»“æ„åˆ†æ

    è§¦å‘æº¶å‰‚åŒ–ç»“æ„åˆ†æï¼Œå°†ç»“æœä¿å­˜åˆ°æ•°æ®åº“

    Args:
        job_id: ä»»åŠ¡ ID
        cutoff: æº¶å‰‚åŒ–å£³å±‚æˆªæ–­è·ç¦» (Ã…)ï¼Œé»˜è®¤ 3.0
    """
    from app.models.result import SolvationStructure
    from app.services.solvation import analyze_solvation_structures, generate_solvation_statistics
    from app.dependencies import check_resource_permission

    # è·å–ä»»åŠ¡
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ•°æ®éš”ç¦»ï¼šæ£€æŸ¥æƒé™ï¼ˆç®¡ç†å‘˜å¯ä»¥è®¿é—®æ‰€æœ‰æ•°æ®ï¼Œæ™®é€šç”¨æˆ·åªèƒ½è®¿é—®è‡ªå·±çš„æ•°æ®ï¼‰
    check_resource_permission(job.user_id, current_user)

    # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
    if job.status not in [JobStatus.COMPLETED, JobStatus.POSTPROCESSING]:
        raise HTTPException(
            status_code=400,
            detail=f"Job must be COMPLETED or POSTPROCESSING to analyze solvation structures. Current status: {job.status}"
        )

    # æ£€æŸ¥å·¥ä½œç›®å½•
    if not job.work_dir:
        raise HTTPException(status_code=400, detail="Job work directory not found")

    # ä¼˜å…ˆä½¿ç”¨ job.config ä¸­ä¿å­˜çš„ system_snapshotï¼ˆåˆ›å»ºä»»åŠ¡æ—¶çš„é…æ–¹å¿«ç…§ï¼‰
    # è¿™æ ·å¯ä»¥ç¡®ä¿åˆ†æä½¿ç”¨çš„æ˜¯åˆ›å»ºä»»åŠ¡æ—¶çš„é…æ–¹ï¼Œè€Œä¸æ˜¯åç»­ä¿®æ”¹åçš„é…æ–¹
    snapshot = job.config.get("system_snapshot") if job.config else None

    if snapshot:
        electrolyte_data = {
            "cations": snapshot.get("cations"),
            "anions": snapshot.get("anions"),
            "solvents": snapshot.get("solvents"),
        }
    else:
        # å…¼å®¹æ—§ä»»åŠ¡ï¼ˆæ²¡æœ‰å¿«ç…§çš„æƒ…å†µï¼‰ï¼Œä» ElectrolyteSystem è¡¨è¯»å–
        electrolyte = db.query(ElectrolyteSystem).filter(
            ElectrolyteSystem.id == job.system_id
        ).first()

        if not electrolyte:
            raise HTTPException(status_code=404, detail="Electrolyte system not found")

        electrolyte_data = {
            "cations": electrolyte.cations,
            "anions": electrolyte.anions,
            "solvents": electrolyte.solvents,
        }

    try:
        # æ‰§è¡Œæº¶å‰‚åŒ–åˆ†æ
        logger.info(f"å¼€å§‹æº¶å‰‚åŒ–ç»“æ„åˆ†æ: job_id={job_id}, cutoff={cutoff}")
        results = analyze_solvation_structures(
            work_dir=job.work_dir,
            electrolyte_data=electrolyte_data,
            cutoff=cutoff,
        )

        if not results:
            return {
                "success": False,
                "count": 0,
                "message": "æœªæ‰¾åˆ°æº¶å‰‚åŒ–ç»“æ„æ•°æ®ï¼Œè¯·æ£€æŸ¥è½¨è¿¹æ–‡ä»¶",
            }

        # åˆ é™¤æ—§çš„æº¶å‰‚åŒ–ç»“æ„è®°å½•
        db.query(SolvationStructure).filter(
            SolvationStructure.md_job_id == job_id
        ).delete()

        # æ’å…¥æ–°çš„æº¶å‰‚åŒ–ç»“æ„è®°å½•
        for result in results:
            structure = SolvationStructure(
                md_job_id=job_id,
                center_ion=result['center_ion'],
                structure_type=result['structure_type'],
                coordination_num=result['coordination_num'],
                composition=result['composition'],
                mol_order=result.get('mol_order'),  # æ–°å¢ï¼šåˆ†å­é¡ºåºä¿¡æ¯
                file_path=result['file_path'],
                xyz_content=result.get('xyz_content'),  # æ–°å¢ï¼šXYZ å†…å®¹
                snapshot_frame=result['snapshot_frame'],
                description=result['description'],
            )
            db.add(structure)

        db.commit()

        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats = generate_solvation_statistics(results)

        logger.info(f"æº¶å‰‚åŒ–ç»“æ„åˆ†æå®Œæˆ: job_id={job_id}, count={len(results)}")

        return {
            "success": True,
            "count": len(results),
            "statistics": stats,
            "message": f"æˆåŠŸåˆ†æ {len(results)} ä¸ªæº¶å‰‚åŒ–ç»“æ„",
        }

    except Exception as e:
        logger.error(f"æº¶å‰‚åŒ–ç»“æ„åˆ†æå¤±è´¥: job_id={job_id}, error={e}")
        db.rollback()
        raise HTTPException(
            status_code=500,
            detail=f"æº¶å‰‚åŒ–ç»“æ„åˆ†æå¤±è´¥: {str(e)}"
        )


@router.get("/{job_id}/solvation/statistics")
def get_solvation_statistics(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–æº¶å‰‚åŒ–ç»“æ„ç»Ÿè®¡ä¿¡æ¯

    è¿”å›é…ä½æ•°åˆ†å¸ƒã€ç»„æˆåˆ†å¸ƒç­‰ç»Ÿè®¡æ•°æ®
    """
    from app.models.result import SolvationStructure
    from collections import Counter, defaultdict
    from app.dependencies import check_job_permission
    import numpy as np

    # è·å–ä»»åŠ¡
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ•°æ®éš”ç¦»ï¼šæ£€æŸ¥æƒé™ï¼ˆæ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼‰
    check_job_permission(job, current_user)

    # æŸ¥è¯¢æº¶å‰‚åŒ–ç»“æ„
    structures = db.query(SolvationStructure).filter(
        SolvationStructure.md_job_id == job_id
    ).all()

    if not structures:
        return {
            "total_count": 0,
            "average_coordination_number": 0,
            "coordination_distribution": {},
            "composition_distribution": {},
            "molecule_counts": {},
            "anion_coordination_distribution": {},
        }

    # é…ä½æ•°åˆ†å¸ƒ
    cn_dist = Counter(s.coordination_num for s in structures)

    # å¹³å‡é…ä½æ•°
    avg_cn = np.mean([s.coordination_num for s in structures if s.coordination_num])

    # ç»„æˆåˆ†å¸ƒ
    composition_counter = defaultdict(int)
    molecule_counter = Counter()

    # è·å–ç”µè§£æ¶²é…ç½®ä»¥è¯†åˆ«é˜´ç¦»å­
    anion_names = set()
    if job.system:
        # ä» ElectrolyteSystem è·å–é˜´ç¦»å­åç§°
        if job.system.anions:
            for a in job.system.anions:
                if isinstance(a, dict) and a.get('name'):
                    anion_names.add(a['name'])
                elif isinstance(a, str):
                    anion_names.add(a)

    # å¦‚æœæ²¡æœ‰ä»ç”µè§£æ¶²é…ç½®è·å–åˆ°é˜´ç¦»å­ï¼Œä½¿ç”¨å¸¸è§é˜´ç¦»å­åç§°
    if not anion_names:
        anion_names = {'FSI', 'TFSI', 'PF6', 'BF4', 'ClO4', 'NO3', 'SO4', 'Cl', 'Br', 'I'}

    # é˜´ç¦»å­é…ä½æ•°åˆ†å¸ƒ
    anion_cn_dist = Counter()

    for s in structures:
        if s.composition:
            # ç”Ÿæˆç»„æˆé”®
            key = "_".join(f"{k}{v}" for k, v in sorted(s.composition.items()) if v and v > 0)
            if key:
                composition_counter[key] += 1

            # ç»Ÿè®¡å„åˆ†å­æ•°é‡
            anion_count = 0
            for mol_name, count in s.composition.items():
                if count and count > 0:
                    molecule_counter[mol_name] += count
                    # ç»Ÿè®¡é˜´ç¦»å­æ•°é‡
                    if mol_name in anion_names:
                        anion_count += count

            anion_cn_dist[anion_count] += 1

    return {
        "total_count": len(structures),
        "average_coordination_number": round(avg_cn, 2) if avg_cn else 0,
        "coordination_distribution": dict(cn_dist),
        "composition_distribution": dict(composition_counter),
        "molecule_counts": dict(molecule_counter),
        "anion_coordination_distribution": dict(anion_cn_dist),
    }


@router.get("/{job_id}/solvation/structure/{structure_id}")
async def get_solvation_structure_file(
    job_id: int,
    structure_id: int,
    format: str = "file",  # "file" è¿”å›æ–‡ä»¶ä¸‹è½½, "content" è¿”å› XYZ å†…å®¹
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–æº¶å‰‚åŒ–ç»“æ„ XYZ æ–‡ä»¶

    Args:
        format: "file" è¿”å›æ–‡ä»¶ä¸‹è½½, "content" è¿”å› JSON åŒ…å« XYZ å†…å®¹
    """
    from fastapi.responses import FileResponse, Response
    from app.models.result import SolvationStructure
    from app.services.solvation import get_structure_xyz_content
    from app.dependencies import check_job_permission

    # è·å–ä»»åŠ¡
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ•°æ®éš”ç¦»ï¼šæ£€æŸ¥æƒé™ï¼ˆæ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼‰
    check_job_permission(job, current_user)

    # è·å–æº¶å‰‚åŒ–ç»“æ„
    structure = db.query(SolvationStructure).filter(
        SolvationStructure.id == structure_id,
        SolvationStructure.md_job_id == job_id
    ).first()

    if not structure:
        raise HTTPException(status_code=404, detail="Solvation structure not found")

    # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“ä¸­çš„ xyz_contentï¼ˆæ··åˆäº‘æ¶æ„ä¸‹ï¼Œæ–‡ä»¶åœ¨æ ¡å›­ç½‘æœ¬åœ°ï¼‰
    if structure.xyz_content:
        if format == "content":
            # è¿”å› XYZ å†…å®¹ç”¨äº 3D å¯è§†åŒ–
            return {
                "id": structure.id,
                "center_ion": structure.center_ion,
                "coordination_num": structure.coordination_num,
                "composition": structure.composition,
                "xyz_content": structure.xyz_content,
                "filename": f"{structure.center_ion}_{structure.id}.xyz",
            }
        else:
            # è¿”å›æ–‡ä»¶ä¸‹è½½
            return Response(
                content=structure.xyz_content,
                media_type="chemical/x-xyz",
                headers={
                    "Content-Disposition": f'attachment; filename="{structure.center_ion}_{structure.id}.xyz"'
                }
            )

    # å¦‚æœæ²¡æœ‰ xyz_contentï¼Œå°è¯•ä»æœ¬åœ°æ–‡ä»¶è¯»å–ï¼ˆä»…åœ¨æœ¬åœ°éƒ¨ç½²æ—¶æœ‰æ•ˆï¼‰
    if structure.file_path:
        file_path = Path(structure.file_path)
        if file_path.exists():
            if format == "content":
                xyz_content = get_structure_xyz_content(str(file_path))
                if not xyz_content:
                    raise HTTPException(status_code=500, detail="Failed to read structure file")
                return {
                    "id": structure.id,
                    "center_ion": structure.center_ion,
                    "coordination_num": structure.coordination_num,
                    "composition": structure.composition,
                    "xyz_content": xyz_content,
                    "filename": file_path.name,
                }
            else:
                return FileResponse(
                    path=str(file_path),
                    media_type="chemical/x-xyz",
                    filename=file_path.name
                )

    raise HTTPException(status_code=404, detail="Structure file not available")


@router.get("/{job_id}/solvation/system-structure")
def get_system_structure_endpoint(
    job_id: int,
    frame: int = -1,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–æ•´ä¸ªä½“ç³»çš„ç»“æ„ï¼ˆç”¨äº3Då¯è§†åŒ–ï¼‰
    ä¼˜å…ˆä» SystemStructure è¡¨è¯»å–ï¼Œå…¶æ¬¡ä» ResultSummary è¯»å–ï¼Œæœ€åä»æœ¬åœ°è½¨è¿¹æ–‡ä»¶è¯»å–

    Args:
        frame: å¸§ç´¢å¼•ï¼Œ-1 è¡¨ç¤ºæœ€åä¸€å¸§
    """
    from app.models.result import ResultSummary, SystemStructure
    from app.dependencies import check_job_permission

    # è·å–ä»»åŠ¡
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ•°æ®éš”ç¦»ï¼šæ£€æŸ¥æƒé™ï¼ˆæ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼‰
    check_job_permission(job, current_user)

    # ä¼˜å…ˆä» SystemStructure è¡¨è¯»å–ï¼ˆåå¤„ç†ç”Ÿæˆçš„æœ€åä¸€å¸§ï¼‰
    system_structure = db.query(SystemStructure).filter(SystemStructure.md_job_id == job_id).first()
    if system_structure and system_structure.xyz_content:
        return {
            'frame_index': system_structure.frame_index,
            'total_frames': system_structure.total_frames,
            'atom_count': system_structure.atom_count,
            'box': system_structure.box or [0, 0, 0],
            'xyz_content': system_structure.xyz_content,
        }

    # å…¶æ¬¡ä» ResultSummary è¯»å–ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
    summary = db.query(ResultSummary).filter(ResultSummary.md_job_id == job_id).first()
    if summary and summary.system_xyz_content:
        # ä» XYZ å†…å®¹è§£æåŸå­æ•°å’Œç›’å­
        xyz_lines = summary.system_xyz_content.strip().split('\n')
        atom_count = int(xyz_lines[0]) if xyz_lines else 0

        box = [
            summary.box_x or 50.0,
            summary.box_y or 50.0,
            summary.box_z or 50.0,
        ]

        return {
            'frame_index': 0,
            'total_frames': 1,
            'atom_count': atom_count,
            'box': box,
            'xyz_content': summary.system_xyz_content,
        }

    # æœ€åä»æœ¬åœ°è½¨è¿¹æ–‡ä»¶è¯»å–ï¼ˆå¦‚æœå‰ä¸¤ç§éƒ½æ²¡æœ‰ï¼‰
    if not job.work_dir:
        raise HTTPException(status_code=400, detail="Job work directory not found")

    from app.services.solvation import get_system_structure
    result = get_system_structure(job.work_dir, frame)

    if 'error' in result:
        raise HTTPException(status_code=500, detail=result['error'])

    return result


@router.get("/{job_id}/solvation/frame-count")
def get_frame_count_endpoint(
    job_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è·å–è½¨è¿¹æ–‡ä»¶çš„å¸§æ•°
    ä¼˜å…ˆä»æ•°æ®åº“è¯»å–ï¼Œå…¶æ¬¡ä»æ–‡ä»¶ç³»ç»Ÿè¯»å–ï¼ˆæ··åˆäº‘æ¶æ„å…¼å®¹ï¼‰
    """
    from app.services.solvation import get_frame_count
    from app.dependencies import check_job_permission
    from app.models.result import SystemStructure

    # è·å–ä»»åŠ¡
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ•°æ®éš”ç¦»ï¼šæ£€æŸ¥æƒé™ï¼ˆæ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼‰
    check_job_permission(job, current_user)

    # ä¼˜å…ˆä» SystemStructure è¡¨è¯»å–å¸§æ•°ï¼ˆæ··åˆäº‘æ¶æ„ä¸‹çš„ä¸»è¦æ•°æ®æºï¼‰
    system_structure = db.query(SystemStructure).filter(SystemStructure.md_job_id == job_id).first()
    if system_structure and system_structure.total_frames is not None:
        return {"frame_count": system_structure.total_frames}

    # å…¶æ¬¡ä»æ–‡ä»¶ç³»ç»Ÿè¯»å–ï¼ˆæœ¬åœ°éƒ¨ç½²æˆ–æ–‡ä»¶å¯è®¿é—®æ—¶ï¼‰
    if job.work_dir:
        try:
            frame_count = get_frame_count(job.work_dir)
            return {"frame_count": frame_count}
        except Exception as e:
            # æ–‡ä»¶ç³»ç»Ÿè®¿é—®å¤±è´¥ï¼ˆæ··åˆäº‘æ¶æ„ä¸‹å¸¸è§ï¼‰
            pass

    # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›0
    return {"frame_count": 0}


@router.get("/{job_id}/solvation/auto-select")
def auto_select_solvation_structures(
    job_id: int,
    mode: str = "top3",  # "top3" = å æ¯”å‰3, "all" = æ¯ç§1ä¸ª
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    è‡ªåŠ¨æŒ‘é€‰ä¸åŒé…ä½ç»„æˆçš„æº¶å‰‚åŒ–ç»“æ„

    Args:
        mode: é€‰æ‹©æ¨¡å¼
            - "top3": å æ¯”å‰3 - é€‰æ‹©å‡ºç°é¢‘ç‡æœ€é«˜çš„å‰3ç§ç»„æˆ
            - "all": æ¯ç§1ä¸ª - æ¯ç§ç»„æˆé€‰ä¸€ä¸ªä»£è¡¨æ€§ç»“æ„
    """
    from app.models.result import SolvationStructure
    from app.dependencies import check_job_permission
    from collections import defaultdict

    # è·å–ä»»åŠ¡
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ•°æ®éš”ç¦»ï¼šæ£€æŸ¥æƒé™ï¼ˆæ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼‰
    check_job_permission(job, current_user)

    # è·å–æ‰€æœ‰æº¶å‰‚åŒ–ç»“æ„
    structures = db.query(SolvationStructure).filter(
        SolvationStructure.md_job_id == job_id
    ).all()

    if not structures:
        return {
            "total_structures": 0,
            "unique_compositions": 0,
            "selected_structures": []
        }

    # æŒ‰é…ä½ç»„æˆåˆ†ç»„
    composition_groups = defaultdict(list)

    for structure in structures:
        # ç”Ÿæˆç»„æˆé”®ï¼šä¸­å¿ƒç¦»å­-é…ä½“ç»„æˆ
        # ä¾‹å¦‚ï¼šLi-2FSI-1DME-1DMC
        composition_key = _generate_composition_key(
            structure.center_ion,
            structure.composition
        )
        composition_groups[composition_key].append(structure)

    # æŒ‰å‡ºç°æ¬¡æ•°ï¼ˆå æ¯”ï¼‰æ’åº
    sorted_groups = sorted(
        composition_groups.items(),
        key=lambda x: len(x[1]),  # æŒ‰ç»„å†…ç»“æ„æ•°é‡æ’åº
        reverse=True  # æ•°é‡å¤šçš„åœ¨å‰
    )

    # æ ¹æ®æ¨¡å¼é€‰æ‹©ç»„æˆ
    if mode == "top3":
        # å æ¯”å‰3ï¼šé€‰æ‹©å‡ºç°é¢‘ç‡æœ€é«˜çš„å‰3ç§ç»„æˆ
        top_n = 3
        groups_to_select = sorted_groups[:top_n]
    else:
        # æ¯ç§1ä¸ªï¼šé€‰æ‹©æ‰€æœ‰ç»„æˆ
        top_n = len(sorted_groups)
        groups_to_select = sorted_groups

    selected_structures = []
    for composition_key, group in groups_to_select:
        # é€‰æ‹©ç¬¬ä¸€ä¸ªç»“æ„ä½œä¸ºä»£è¡¨
        representative = group[0]
        selected_structures.append({
            "id": representative.id,
            "center_ion": representative.center_ion,
            "coordination_num": representative.coordination_num,
            "composition": representative.composition,
            "composition_key": composition_key,
            "group_size": len(group),  # è¿™ç§ç»„æˆæœ‰å¤šå°‘ä¸ªç»“æ„
            "percentage": round(len(group) / len(structures) * 100, 1),  # å æ¯”
            "snapshot_frame": representative.snapshot_frame,
            "structure_type": representative.structure_type,
        })

    # æŒ‰å æ¯”æ’åºï¼ˆæ•°é‡å¤šçš„åœ¨å‰ï¼‰
    selected_structures.sort(
        key=lambda s: s["group_size"],
        reverse=True
    )

    return {
        "total_structures": len(structures),
        "unique_compositions": len(composition_groups),
        "mode": mode,
        "selected_count": len(selected_structures),
        "selected_structures": selected_structures
    }


def _generate_composition_key(center_ion: str, composition: dict) -> str:
    """
    ç”Ÿæˆé…ä½ç»„æˆé”®

    Args:
        center_ion: ä¸­å¿ƒç¦»å­ï¼Œå¦‚ "Li"
        composition: é…ä½“ç»„æˆå­—å…¸ï¼Œå¦‚ {"FSI": 2, "DME": 1, "DMC": 1}

    Returns:
        ç»„æˆé”®å­—ç¬¦ä¸²ï¼Œå¦‚ "Li-2FSI-1DME-1DMC"
    """
    if not composition:
        return f"{center_ion}-empty"

    # æŒ‰é…ä½“åç§°æ’åºï¼Œç¡®ä¿ç›¸åŒç»„æˆç”Ÿæˆç›¸åŒçš„é”®
    sorted_ligands = sorted(composition.items())

    # æ„å»ºé”®ï¼šä¸­å¿ƒç¦»å­-æ•°é‡é…ä½“å
    parts = [center_ion]
    for ligand_name, count in sorted_ligands:
        if count > 0:
            parts.append(f"{count}{ligand_name}")

    return "-".join(parts)


@router.get("/{job_id}/solvation/export-data")
def export_solvation_data(
    job_id: int,
    format: str = "json",  # "json" æˆ– "csv"
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    å¯¼å‡ºæº¶å‰‚åŒ–ç»“æ„æ•°æ®ï¼ˆç”¨äºç”¨æˆ·è‡ªè¡Œç»˜å›¾ï¼‰

    Args:
        format: "json" æˆ– "csv"
    """
    from fastapi.responses import Response
    from app.models.result import SolvationStructure
    from app.dependencies import check_job_permission
    import csv
    import io

    # è·å–ä»»åŠ¡
    job = db.query(MDJob).filter(MDJob.id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ•°æ®éš”ç¦»ï¼šæ£€æŸ¥æƒé™ï¼ˆæ”¯æŒå…¬å¼€æ•°æ®è®¿é—®ï¼‰
    check_job_permission(job, current_user)

    # æŸ¥è¯¢æº¶å‰‚åŒ–ç»“æ„
    structures = db.query(SolvationStructure).filter(
        SolvationStructure.md_job_id == job_id
    ).order_by(SolvationStructure.id).all()

    if not structures:
        raise HTTPException(status_code=404, detail="No solvation data found")

    # è·å–æ‰€æœ‰åˆ†å­ç±»å‹
    all_mol_types = set()
    for s in structures:
        if s.composition:
            all_mol_types.update(s.composition.keys())
    all_mol_types = sorted(all_mol_types)

    if format == "csv":
        # å¯¼å‡ºä¸º CSV
        output = io.StringIO()
        writer = csv.writer(output)

        # è¡¨å¤´
        headers = ["id", "center_ion", "coordination_num"] + all_mol_types + ["description"]
        writer.writerow(headers)

        # æ•°æ®è¡Œ
        for s in structures:
            row = [
                s.id,
                s.center_ion,
                s.coordination_num,
            ]
            for mol in all_mol_types:
                row.append(s.composition.get(mol, 0) if s.composition else 0)
            row.append(s.description or "")
            writer.writerow(row)

        csv_content = output.getvalue()
        return Response(
            content=csv_content,
            media_type="text/csv",
            headers={"Content-Disposition": f"attachment; filename=solvation_job{job_id}.csv"}
        )

    # é»˜è®¤ JSON æ ¼å¼
    data = {
        "job_id": job_id,
        "total_count": len(structures),
        "molecule_types": all_mol_types,
        "structures": [
            {
                "id": s.id,
                "center_ion": s.center_ion,
                "coordination_num": s.coordination_num,
                "composition": s.composition,
                "description": s.description,
            }
            for s in structures
        ],
        # ç»Ÿè®¡æ•°æ®
        "statistics": {
            "coordination_distribution": dict(Counter(s.coordination_num for s in structures)),
            "average_coordination_number": round(
                sum(s.coordination_num for s in structures) / len(structures), 2
            ) if structures else 0,
        }
    }

    return data
