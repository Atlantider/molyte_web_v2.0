#!/usr/bin/env python3
"""
æ‰¹é‡ä¿®å¤æ‰€æœ‰å› COSé—®é¢˜è€Œå¤±è´¥çš„ä»»åŠ¡
æ¨¡æ‹Ÿ polling worker çš„å®Œæˆå¤„ç†æµç¨‹
"""

import os
import sys
import subprocess
import yaml
import json
import requests
from datetime import datetime
from pathlib import Path

# å¯¼å…¥è…¾è®¯äº‘COS SDK
try:
    from qcloud_cos import CosConfig, CosS3Client
except ImportError:
    print("è¯·å®‰è£…è…¾è®¯äº‘ COS SDK: pip install cos-python-sdk-v5")
    exit(1)

# éœ€è¦ä¿®å¤çš„ä»»åŠ¡åˆ—è¡¨ (åªåŒ…å«å·¥ä½œç›®å½•å­˜åœ¨çš„ä»»åŠ¡)
FAILED_TASKS = [
    {
        'id': 178,
        'type': 'md',
        'work_dir': '/public/home/xiaoji/molyte_web/data/md_work/EL-20251205-0001-Li-PF6-EC-DEC-PC-MD1-298K',
        'name': 'EL-20251205-0001-Li-PF6-EC-DEC-PC-MD1-298K'
    },
    {
        'id': 1836,
        'type': 'qc',
        'work_dir': '/public/home/xiaoji/molyte_web/data/qc_work/QC-1836-MD176_dimer_PF6_1507',
        'name': 'QC-1836-MD176_dimer_PF6_1507'
    },
    {
        'id': 1838,
        'type': 'qc',
        'work_dir': '/public/home/xiaoji/molyte_web/data/qc_work/QC-1838-MD176_intermediate_DEC_1_PF6_1_1507',
        'name': 'QC-1838-MD176_intermediate_DEC_1_PF6_1_1507'
    },
    {
        'id': 1839,
        'type': 'qc',
        'work_dir': '/public/home/xiaoji/molyte_web/data/qc_work/QC-1839-MD176_intermediate_DEC_2_1507',
        'name': 'QC-1839-MD176_intermediate_DEC_2_1507'
    },
    {
        'id': 1840,
        'type': 'qc',
        'work_dir': '/public/home/xiaoji/molyte_web/data/qc_work/QC-1840-MD176_intermediate_DEC_2_PF6_1_1507',
        'name': 'QC-1840-MD176_intermediate_DEC_2_PF6_1_1507'
    }
]

def load_config():
    """åŠ è½½polling workeré…ç½®"""
    try:
        config_path = Path('/public/home/xiaoji/molyte_web/deployment/polling_worker_config_tencent.yaml')
        if not config_path.exists():
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return None
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        return config
        
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return None

def init_cos_client(config):
    """åˆå§‹åŒ–COSå®¢æˆ·ç«¯"""
    try:
        if 'cos' not in config:
            print("âŒ é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°COSé…ç½®")
            return None, None
        
        cos_config = config['cos']
        cos_cfg = CosConfig(
            Region=cos_config['region'],
            SecretId=cos_config['secret_id'],
            SecretKey=cos_config['secret_key'],
            Scheme='https'
        )
        
        cos_client = CosS3Client(cos_cfg)
        cos_bucket = cos_config['bucket']
        
        print(f"âœ… COSå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        return cos_client, cos_bucket
        
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–COSå®¢æˆ·ç«¯å¤±è´¥: {e}")
        return None, None

def check_work_directory(work_dir):
    """æ£€æŸ¥å·¥ä½œç›®å½•"""
    try:
        work_path = Path(work_dir)
        if not work_path.exists():
            print(f"âŒ å·¥ä½œç›®å½•ä¸å­˜åœ¨: {work_dir}")
            return False
        
        files = list(work_path.iterdir())
        print(f"ğŸ“ å·¥ä½œç›®å½•: {work_dir}")
        print(f"   ğŸ“‹ å…±æœ‰ {len(files)} ä¸ªæ–‡ä»¶")
        return True
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å·¥ä½œç›®å½•å¤±è´¥: {e}")
        return False

def upload_results_selective(cos_client, cos_bucket, config, job_id, work_dir, job_type):
    """æŒ‰ç…§polling workerçš„ç­–ç•¥é€‰æ‹©æ€§ä¸Šä¼ ç»“æœæ–‡ä»¶åˆ°COS"""
    try:
        work_path = Path(work_dir)
        
        # ä½¿ç”¨polling workerçš„ä¸Šä¼ é…ç½®
        essential_patterns = config['upload']['essential_files']
        excluded_patterns = config['upload'].get('excluded_files', [])
        max_size = config['upload']['max_file_size'] * 1024 * 1024  # MB to bytes
        
        # è·å–ç»“æœå‰ç¼€
        if job_type.lower() == 'md':
            result_prefix = config['cos'].get('md_result_prefix', 'MD_results/')
        else:
            result_prefix = config['cos'].get('qc_result_prefix', 'QC_results/')
        
        uploaded_files = []
        
        print(f"ğŸ“‹ ä½¿ç”¨essentialæ–‡ä»¶æ¨¡å¼: {essential_patterns}")
        
        # åªä¸Šä¼ essentialæ–‡ä»¶
        for pattern in essential_patterns:
            files = list(work_path.glob(pattern))
            for file_path in files:
                if not file_path.is_file():
                    continue
                
                # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
                excluded = False
                for exclude_pattern in excluded_patterns:
                    if file_path.match(exclude_pattern):
                        print(f"â­ï¸ è·³è¿‡æ’é™¤çš„æ–‡ä»¶: {file_path.name}")
                        excluded = True
                        break
                if excluded:
                    continue
                
                # æ£€æŸ¥æ–‡ä»¶å¤§å°
                file_size = file_path.stat().st_size
                if file_size > max_size:
                    print(f"âš ï¸ æ–‡ä»¶ {file_path.name} ({file_size/1024/1024:.1f}MB) è¶…è¿‡å¤§å°é™åˆ¶ï¼Œè·³è¿‡")
                    continue
                
                if file_size == 0:
                    print(f"â­ï¸ è·³è¿‡ç©ºæ–‡ä»¶: {file_path.name}")
                    continue
                
                # æ„å»ºCOS key
                cos_key = f"{result_prefix}{job_id}/{file_path.name}"
                
                print(f"ğŸ“¤ ä¸Šä¼ æ–‡ä»¶: {file_path.name} ({file_size/1024/1024:.1f}MB)")
                
                with open(file_path, 'rb') as f:
                    cos_client.put_object(
                        Bucket=cos_bucket,
                        Body=f,
                        Key=cos_key
                    )
                
                uploaded_files.append(cos_key)
                print(f"   âœ… ä¸Šä¼ æˆåŠŸ")
        
        print(f"âœ… å…±ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶åˆ°COS")
        return len(uploaded_files) > 0, uploaded_files
            
    except Exception as e:
        print(f"âŒ ä¸Šä¼ æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False, []

def parse_md_results(work_dir):
    """è§£æMDç»“æœ"""
    try:
        work_path = Path(work_dir)
        results = {}
        
        # æŸ¥æ‰¾RDFæ–‡ä»¶
        rdf_files = list(work_path.glob("out_rdf.dat"))
        if rdf_files:
            print(f"ğŸ“Š è§£æRDFæ–‡ä»¶: {rdf_files[0].name}")
            results['rdf'] = str(rdf_files[0])
        
        # æŸ¥æ‰¾MSDæ–‡ä»¶
        msd_files = list(work_path.glob("out_*_msd.dat"))
        for msd_file in msd_files:
            print(f"ğŸ“Š è§£æMSDæ–‡ä»¶: {msd_file.name}")
            results[f'msd_{msd_file.stem}'] = str(msd_file)
        
        print(f"âœ… MDç»“æœè§£æå®Œæˆ: {len(results)} ä¸ªç»“æœæ–‡ä»¶")
        return results
        
    except Exception as e:
        print(f"âŒ è§£æMDç»“æœå¤±è´¥: {e}")
        return {}

def parse_qc_results(work_dir):
    """è§£æQCç»“æœ"""
    try:
        work_path = Path(work_dir)
        results = {}
        
        # æŸ¥æ‰¾è¾“å‡ºæ–‡ä»¶
        out_files = list(work_path.glob("*.out"))
        log_files = list(work_path.glob("*.log"))
        fchk_files = list(work_path.glob("*.fchk"))
        
        if out_files:
            results['output_file'] = str(out_files[0])
        if log_files:
            results['log_file'] = str(log_files[0])
        if fchk_files:
            results['fchk_file'] = str(fchk_files[0])
        
        print(f"âœ… QCç»“æœè§£æå®Œæˆ: {len(results)} ä¸ªç»“æœæ–‡ä»¶")
        return results
        
    except Exception as e:
        print(f"âŒ è§£æQCç»“æœå¤±è´¥: {e}")
        return {}

def upload_results_to_api(config, job_id, job_type, results):
    """ä¸Šä¼ ç»“æœåˆ°åç«¯API"""
    try:
        api_base_url = config['api']['base_url']
        api_headers = {
            'Content-Type': 'application/json',
            'Authorization': f"Bearer {config['api']['worker_token']}"
        }
        
        if job_type.lower() == 'md':
            endpoint = f"{api_base_url}/workers/jobs/{job_id}/md_results"
        else:
            endpoint = f"{api_base_url}/workers/jobs/{job_id}/qc_results"
        
        print(f"ğŸ“Š ä¸Šä¼ {job_type.upper()}ç»“æœåˆ°API: {endpoint}")
        
        response = requests.post(
            endpoint,
            headers=api_headers,
            json=results,
            timeout=config['api']['timeout']
        )
        
        if response.status_code == 200:
            print(f"âœ… {job_type.upper()}ç»“æœä¸Šä¼ æˆåŠŸ")
            return True
        else:
            print(f"âŒ {job_type.upper()}ç»“æœä¸Šä¼ å¤±è´¥: HTTP {response.status_code}")
            print(f"   å“åº”: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ ä¸Šä¼ {job_type.upper()}ç»“æœå¤±è´¥: {e}")
        return False

def update_job_status(config, job_id, job_type, status='COMPLETED', result_files=None):
    """æ›´æ–°ä»»åŠ¡çŠ¶æ€åˆ°è…¾è®¯äº‘åç«¯"""
    try:
        api_base_url = config['api']['base_url']
        api_headers = {
            'Content-Type': 'application/json',
            'Authorization': f"Bearer {config['api']['worker_token']}"
        }
        
        endpoint = f"{api_base_url}/workers/jobs/{job_id}/status"
        
        data = {
            'status': status,
            'job_type': job_type.upper(),
            'worker_name': config['worker']['name'],
            'progress': 100.0,
            'error_message': None
        }
        
        if result_files:
            data['result_files'] = result_files
        
        print(f"ğŸ”„ æ›´æ–°ä»»åŠ¡çŠ¶æ€åˆ°åç«¯: {endpoint}")
        
        response = requests.put(
            endpoint,
            headers=api_headers,
            json=data,
            timeout=config['api']['timeout']
        )
        
        if response.status_code == 200:
            print(f"âœ… ä»»åŠ¡ {job_id} çŠ¶æ€å·²æ›´æ–°ä¸º {status}")
            return True
        else:
            print(f"âŒ æ›´æ–°çŠ¶æ€å¤±è´¥: HTTP {response.status_code}")
            print(f"   å“åº”: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
        return False

def fix_single_task(config, cos_client, cos_bucket, task):
    """ä¿®å¤å•ä¸ªä»»åŠ¡"""
    print(f"\n{'='*60}")
    print(f"ğŸ”§ å¼€å§‹ä¿®å¤ä»»åŠ¡ {task['id']}: {task['name']}")
    print(f"   ç±»å‹: {task['type'].upper()}")
    print(f"   å·¥ä½œç›®å½•: {task['work_dir']}")
    
    # 1. æ£€æŸ¥å·¥ä½œç›®å½•
    if not check_work_directory(task['work_dir']):
        print(f"âŒ ä»»åŠ¡ {task['id']} ä¿®å¤å¤±è´¥: å·¥ä½œç›®å½•ä¸å­˜åœ¨")
        return False
    
    # 2. ä¸Šä¼ ç»“æœæ–‡ä»¶åˆ°COS
    print(f"\nğŸ“¤ æ­¥éª¤1: ä¸Šä¼ ç»“æœæ–‡ä»¶åˆ°COS...")
    upload_success, uploaded_files = upload_results_selective(
        cos_client, cos_bucket, config, task['id'], task['work_dir'], task['type']
    )
    
    if not upload_success:
        print(f"âŒ ä»»åŠ¡ {task['id']} ä¿®å¤å¤±è´¥: æ–‡ä»¶ä¸Šä¼ å¤±è´¥")
        return False
    
    # 3. è§£æç»“æœ
    print(f"\nğŸ“Š æ­¥éª¤2: è§£æ{task['type'].upper()}ç»“æœ...")
    if task['type'].lower() == 'md':
        results = parse_md_results(task['work_dir'])
    else:
        results = parse_qc_results(task['work_dir'])
    
    # 4. ä¸Šä¼ ç»“æœåˆ°API
    if results:
        print(f"\nğŸ“¡ æ­¥éª¤3: ä¸Šä¼ {task['type'].upper()}ç»“æœåˆ°API...")
        api_success = upload_results_to_api(config, task['id'], task['type'], results)
        if not api_success:
            print(f"âš ï¸ {task['type'].upper()}ç»“æœä¸Šä¼ åˆ°APIå¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œ...")
    else:
        print(f"âš ï¸ æœªèƒ½è§£æ{task['type'].upper()}ç»“æœæ•°æ®")
    
    # 5. æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºCOMPLETED
    print(f"\nğŸ”„ æ­¥éª¤4: æ›´æ–°ä»»åŠ¡çŠ¶æ€...")
    status_success = update_job_status(config, task['id'], task['type'], 'COMPLETED', uploaded_files)
    
    if not status_success:
        print(f"âŒ ä»»åŠ¡ {task['id']} ä¿®å¤å¤±è´¥: çŠ¶æ€æ›´æ–°å¤±è´¥")
        return False
    
    print(f"âœ… ä»»åŠ¡ {task['id']} ä¿®å¤å®Œæˆ!")
    print(f"   ä¸Šä¼ æ–‡ä»¶æ•°: {len(uploaded_files)}")
    print(f"   è§£æç»“æœæ•°: {len(results)}")
    print(f"   ä»»åŠ¡çŠ¶æ€: COMPLETED")
    
    return True

def main():
    """ä¸»å‡½æ•° - æ‰¹é‡ä¿®å¤æ‰€æœ‰å¤±è´¥çš„ä»»åŠ¡"""
    print("ğŸ”§ å¼€å§‹æ‰¹é‡ä¿®å¤å› COSé—®é¢˜è€Œå¤±è´¥çš„ä»»åŠ¡...")
    print(f"ğŸ“‹ å…±æœ‰ {len(FAILED_TASKS)} ä¸ªä»»åŠ¡éœ€è¦ä¿®å¤")
    
    # 1. åŠ è½½é…ç½®
    config = load_config()
    if not config:
        return False
    
    # 2. åˆå§‹åŒ–COSå®¢æˆ·ç«¯
    cos_client, cos_bucket = init_cos_client(config)
    if not cos_client:
        return False
    
    # 3. æ‰¹é‡ä¿®å¤ä»»åŠ¡
    success_count = 0
    failed_count = 0
    
    for task in FAILED_TASKS:
        try:
            if fix_single_task(config, cos_client, cos_bucket, task):
                success_count += 1
            else:
                failed_count += 1
        except Exception as e:
            print(f"âŒ ä»»åŠ¡ {task['id']} ä¿®å¤æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            failed_count += 1
    
    # 4. æ€»ç»“
    print(f"\n{'='*60}")
    print(f"ğŸ‰ æ‰¹é‡ä¿®å¤å®Œæˆ!")
    print(f"   âœ… æˆåŠŸä¿®å¤: {success_count} ä¸ªä»»åŠ¡")
    print(f"   âŒ ä¿®å¤å¤±è´¥: {failed_count} ä¸ªä»»åŠ¡")
    print(f"   ğŸ“Š æ€»è®¡: {len(FAILED_TASKS)} ä¸ªä»»åŠ¡")
    
    if success_count > 0:
        print(f"\nğŸ‰ æˆåŠŸä¿®å¤çš„ä»»åŠ¡å‰ç«¯çŠ¶æ€åº”è¯¥å·²æ›´æ–°!")
    
    return success_count > 0

if __name__ == "__main__":
    try:
        success = main()
        if success:
            print(f"\nğŸ‰ è„šæœ¬æ‰§è¡ŒæˆåŠŸ!")
            sys.exit(0)
        else:
            print(f"\nğŸ’¥ è„šæœ¬æ‰§è¡Œå¤±è´¥!")
            sys.exit(1)
    except KeyboardInterrupt:
        print(f"\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ è„šæœ¬æ‰§è¡Œæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        sys.exit(1)
